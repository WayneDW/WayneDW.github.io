<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-07-08T15:50:21-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Wei Deng / 邓伟</title><subtitle>Ph.D. candidate in Applied Math at Purdue University</subtitle><author><name>Wei Deng</name></author><entry><title type="html">The Conjoined Triangle of Flow, Diffusion, and PDE</title><link href="http://localhost:4000/posts/flow_diffusion_PDE/" rel="alternate" type="text/html" title="The Conjoined Triangle of Flow, Diffusion, and PDE" /><published>2023-07-01T00:00:00-07:00</published><updated>2023-07-01T00:00:00-07:00</updated><id>http://localhost:4000/posts/flow-diffusion-PDE</id><content type="html" xml:base="http://localhost:4000/posts/flow_diffusion_PDE/"><![CDATA[<!-- https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference -->

<h3 id="diffusion-process">Diffusion Process</h3>

<p>Consider a diffusion process that solves the Itô’s SDE <a class="citation" href="#oksendal2003stochastic">(Øksendal, 2003)</a>:</p>

\[\begin{align}
\mathrm{d} \mathrm{X}_t=\boldsymbol{\mathrm{v}}(\mathrm{X}_t, t) \mathrm{d} t + \sigma(X_t) \mathrm{d} \mathrm{W}_t.\notag
\end{align}\]

<p>Denote by $\mathrm{P}_t$ the transition function of Markov process</p>

\[\begin{align}
(\mathrm{P}_t f)(x)=\int f(y)\mathrm{P}(t, x, \mathrm{d} y)\notag.
\end{align}\]

<p>Define the generator $\mathscr{L}f=\lim \frac{\mathrm{P}_t f - f}{y}$, where $\mathrm{P}_t=e^{t \mathscr{L}}$. Analyzing the transition of the conditional expectation $\mathbb{E}(f(\mathrm{X}_t)|\mathrm{X}_s=x)$, we have the backward Kolmogorov equation</p>

\[\begin{align}
\mathscr{L}&amp;=\boldsymbol{\mathrm{v}}\cdot \nabla + \frac{1}{2} \Sigma:D^2\notag\\
           &amp;=\sum_{j=1}^d \mathrm{v}_j\frac{\partial}{\partial x_j} + \frac{1}{2}\sum_{i,j=1}^d \Sigma_{ij}\frac{\partial^2}{\partial x_i \partial x_j}\notag.
\end{align}\]

<p>where $\nabla$ and  $\nabla\cdot$ denote the gradient and the divergence in $\mathbb{R}^d$, $\Sigma(x)=\sigma(x) \sigma(x)^\intercal$ and $D^2$ denotes the Hessian matrix.</p>

<!-- # https://openreview.net/pdf?id=x9tAJ3_N0k -->

<h3 id="fokker-planck-equation">Fokker-Planck Equation</h3>

<p>Further define the semigroup $\mathrm{P}_t^{*}$ that acts on probability measures</p>

\[\begin{align}
\mathrm{P}^{*}_t \mu(\Gamma)=\int \mathrm{P}(t, x, \Gamma)\mathrm{d} \mu(x)\notag.
\end{align}\]

<p>The semigroup $\mathrm{P}_t$ and $\mathrm{P}_t^{*}$ are adjoint in $L^2$ such that</p>

\[\begin{align}
\int (\mathrm{P}_t f)\mathrm{d}\mu=\int f\mathrm{d}(\mathrm{P}_t^{*}\mu)\notag,
\end{align}\]

<p>which yields</p>

\[\begin{align}
\int \mathscr{L} f h \mathrm{d} x = \int f \mathscr{L}^* h \mathrm{d}x, \text{ where } \mathrm{P}_t^*=e^{t {\mathscr{L}}^*}.\notag
\end{align}\]

<p>Let $p_t$ denote the law of the Markov process at time $t$. The law of $p_t$ follows that</p>

\[\begin{align}
\frac{\partial p_t}{\partial t} =\mathscr{L}^* p_t,\notag
\end{align}\]

<p>which is the Fokker-Planck equation. Analyzing the evolution of the probability densities, we have</p>

\[\begin{align}
\mathscr{L}^{*} p_t&amp;=\nabla \cdot \bigg(-\boldsymbol{\mathrm{v}} p_t + \frac{1}{2} \nabla\cdot\big(\Sigma p_t\big)\bigg). \notag \\
                &amp;=\nabla \cdot \bigg(-\boldsymbol{\mathrm{v}} p_t + \frac{1}{2} \big(\nabla\cdot \Sigma\big) p_t + \frac{1}{2} \Sigma \nabla p_t \bigg). \notag \\
                &amp;=\nabla \cdot \bigg(-\underbrace{\bigg(\boldsymbol{\mathrm{v}} - \frac{1}{2} \big(\nabla\cdot \Sigma\big) - \frac{1}{2} \Sigma \nabla \log p_t\bigg)}_{\boldsymbol{\nu}_t} p_t \bigg), \notag \\
\end{align}\]

<p>where the last equality follows by $\nabla \log p_t = \frac{\nabla p_t}{p_t}$.</p>

<h3 id="probability-flow">Probability Flow</h3>

<p>Denote by $\boldsymbol{\nu}=\boldsymbol{\mathrm{v}} - \frac{1}{2} \big(\nabla\cdot \Sigma\big) - \frac{1}{2} \Sigma \nabla \log p$, the FPE is recased as the transport equation <a class="citation" href="#OT_applied_math">(Santambrogio, 2015)</a> or continuity equation in fluid dynamics <a class="citation" href="#log_concave_sampling">(Chewi, 2023)</a>.</p>

\[\begin{align}
\partial_t p_t =- \nabla \cdot ({\boldsymbol{\nu_t}} p_t).\notag
\end{align}\]

<p>Interestingly, it corresponds to the probability flow ODE <a class="citation" href="#score_sde">(Song et al., 2021)</a></p>

\[\begin{align}
\mathrm{d} X_t={\boldsymbol{\nu_t}}(X_t) \mathrm{d} t.\notag
\end{align}\]

<p>Apply the instantaneous change of variables <a class="citation" href="#neural_ode">(Chen et al., 2018)</a>, the <strong>log-likelihood</strong> of $p_0(x)$ follows that</p>

\[\begin{align}
\log p_0(x)=\log p_T(x) + \int_0^T \nabla \cdot {\boldsymbol{\nu_t}} \mathrm{d} t,\notag
\end{align}\]

<p>which provides an elegant way to compute the likelihood for diffusion models.</p>

<p>In practice, it is expensive to evaluate the divergence $\nabla \cdot {\boldsymbol{\nu_t}}$. We can adopt the Hutchinson trace estimator <a class="citation" href="#Hutchinson89">(Hutchinson, 1989)</a>.</p>

\[\begin{align}
\nabla \cdot {\boldsymbol{\nu_t}} = \mathbb{E} \big[\epsilon^\intercal \nabla {\boldsymbol{\nu_t}} \epsilon \big],
\end{align}\]

<p>where $\nabla {\boldsymbol{\nu_t}}$ is the Jaconbian of ${\boldsymbol{\nu_t}}$; the random variable $\epsilon$ is a standard Gaussian vector and $\epsilon^\intercal \nabla {\boldsymbol{\nu_t}}$ can be efficiently computed using reverse-mode automatic differentiation.</p>]]></content><author><name>Wei Deng</name></author><category term="Diffusion Model" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Blogging for Self-Reflection and Sharing</title><link href="http://localhost:4000/posts/why_blog/" rel="alternate" type="text/html" title="Blogging for Self-Reflection and Sharing" /><published>2023-05-23T00:00:00-07:00</published><updated>2023-05-23T00:00:00-07:00</updated><id>http://localhost:4000/posts/Why-Blog</id><content type="html" xml:base="http://localhost:4000/posts/why_blog/"><![CDATA[During the early stages of my Ph.D. career, I found myself overwhelmed as I delved into the intricate and enigmatic connections found within stochastic differential equations, partial differential equations, dynamical systems, functional analysis, and geometry. I was on the verge of giving up until I came across a series of enlightening slides and blogs that brought clarity to my thoughts. 

<!-- After graduation, I decided to maintain a blog to record my thoughts. I believe writing blogs has a few clear advantages. -->



### Self-Reflection

Feynman ever said that 

> What I Cannot Create, I Do Not Understand.

Many intriguing formulas and theorems may seem deceptively simple solely based on their names, but their true essence is revealed when we meticulously write them down and analyze the details step by step. Maintaining a blog not only helps me organize my thoughts but also allows me to delve deeper into my understanding.

### Blogs v.s. Papers

The pursuit of knowledge has motivated me to utilize publishing as a means of continuous learning. However, the pressures associated with publishing and the emphasis on novelty sometimes lead papers astray from their original purpose.

<!-- : solve problems using appropriate tools or interpretations. The varying interpretations of what is considered "appropriate" ultimately contribute to the overwhelming volume of publications in the world {% cite slowed_science %}. -->


If we confine ourselves solely to reading published works, we may find ourselves lost amidst an ocean of countless novel ideas, while the most crucial ones remain inadequately comprehended by young researchers like myself. Inspired by the numerous enlightening blogs, which I listed in my github page, I decided to maintain a blog to express appreciation for renowned findings. 

<!-- My Blogs may not generate new knowledge, but rather devote to disseminating the seldom-explored paths discovered by others.  -->

<!-- ### Knowledge Sharing

I am not generating new knowledge, but rather devoted to disseminating the seldom-explored paths discovered by others. I believe that valuable pathways deserve acknowledgment from a broader audience through various mediums like textbooks, publications, and blogs. Over the course of China's millennia-long history, countless invaluable customs have been lost simply due to insufficient awareness. -->


#### Acknowledgement

Thank you, Nan Jiang, Gregory Gundersen, and ChatGPT, for your assistance and suggestions in building this cool website.]]></content><author><name>Wei Deng</name></author><summary type="html"><![CDATA[During the early stages of my Ph.D. career, I found myself overwhelmed as I delved into the intricate and enigmatic connections found within stochastic differential equations, partial differential equations, dynamical systems, functional analysis, and geometry. I was on the verge of giving up until I came across a series of enlightening slides and blogs that brought clarity to my thoughts.]]></summary></entry><entry><title type="html">Coupling by Reflection (II)</title><link href="http://localhost:4000/posts/coupling_by_reflection/" rel="alternate" type="text/html" title="Coupling by Reflection (II)" /><published>2023-05-20T00:00:00-07:00</published><updated>2023-05-20T00:00:00-07:00</updated><id>http://localhost:4000/posts/Coupling-by-Reflection</id><content type="html" xml:base="http://localhost:4000/posts/coupling_by_reflection/"><![CDATA[### Limitations of Synchronous Coupling

Given a $\kappa$-strongly convex drift $U$, we can apply the synchronous coupling for the diffusion process

$$\begin{align}
  \mathrm{d}X_t = U(X_t)\mathrm{d}t+\mathrm{d}W_t\notag\\
  \mathrm{d}Y_t = U(Y_t)\mathrm{d}t+\mathrm{d}W_t.\notag\\
\end{align}$$

Eliminating the Brownian motion, we obtain a contractivity property

$$\begin{align}
  \|X_t-Y_t\|\leq \|X_0-Y_0\|^2 \exp(-\kappa t).\notag
\end{align}$$

However, we cannot easily obtain the desired contraction when $U$ is not strongly convex. To address this issue, one should consider a more general coupling method based on a specic metric instead of the standard Euclidean metric. The diffusions may not contract almost surely, but rather in the average sense.

### Reflection Coupling

Define the coupling time $T_c=\inf \\{ t\geq 0  \| X_t =Y_t \\}$. By definition, we know that $X_t=Y_t$ for $t\geq T_c$ {% cite mufa_chen %} {% cite reflection_coupling %} {% cite reflection_coupling_2 %}  {% cite coupling_hmc %}. When the drift term $U$ is zero, we observe that $\\|X_t-Y_t\\|$ remains fixed for any $t$ and synchronous coupling doesn't induce any contraction. 

Let's explore an alternative coupling where the Brownian motion moves in the opposite direction. We anticipate with some probability the processes will merge [Why?].

$$\begin{align}
  \mathrm{d}X_t &= U(X_t)\mathrm{d}t+\mathrm{d}W_t\notag\\
  \mathrm{d}Y_t &= U(Y_t)\mathrm{d}t+(\mathrm{I} - 2\cdot e_t e_t^{\intercal})\mathrm{d}W_t,\notag\\
\end{align}$$

where $e_t=\mathbb{I}\_{[X_t\neq Y_t]}\cdot \frac{X_t-Y_t}{\\|X_t-Y_t\\|}$ and one can identify that $\widetilde W_t=\int_0^t \big[\mathrm{I} - 2\cdot e_s e_s^{\intercal} \big]\mathrm{d} s$ is also a Brownian motion. In addition, $e_t e_t^{\intercal}$ is the orthogonal projection onto the unit vector $e_t$ [\[Hint\]](https://textbooks.math.gatech.edu/ila/projections.html) and you can easily check that $e_t$ is the eigenvector of $\mathrm{I} - 2\cdot e_t e_t^{\intercal}$ with one eigenvalue $-1$..


### Supermartingales 

We first show $\exp(c\cdot t)f(G_t)$ is a supermartingale, where $G_t=\\|X_t-Y_t\\|$.

Apply Ito's lemma to $f(G_t)$, where $f$ is a concave function to induce a new distance metric $d_f(X, Y)=f(\\|X-Y\\|)$ {% cite reflection_coupling %}.

$$\begin{align}
  \mathrm{d} f(G_t)=2f'(R_t)\mathrm{d}W_t+\bigg\{f'(G_t)\cdot \bigg\langle U(X_t)-U(Y_t), \frac{X_t-Y_t}{\|X_t-Y_t\|}\bigg\rangle +2f''(G_t)\bigg\} \mathrm{d}t.\notag
\end{align}$$

Assume $\langle U(X_t)-U(Y_t), X_t-Y_t\rangle \leq -\kappa(r) \frac{\\|X_t-Y_t\\|^2}{2}$, where $\kappa(r)$ is not necessarily positive

$$\begin{align}
  \bigg\langle U(X_t)-U(Y_t), \frac{X_t-Y_t}{\|X_t-Y_t\|}\bigg\rangle \leq -\frac{1}{2} \cdot G_t \cdot\kappa(G_t). \notag
\end{align}$$

Further including the integration factor $\exp(c\cdot t)$, we have

$$\begin{align}
  \dfrac{\mathrm{d} \bigg[\exp(c\cdot t)f(G_t)\bigg]}{\exp(c\cdot t)}\leq 2f'(R_t) \mathrm{d}W_t + \bigg[-\frac{1}{2} G_t \cdot\kappa(G_t) f'(G_t)+2f''(G_t)+c \cdot f(G_t)\bigg]\mathrm{d}t. \notag
\end{align}$$

In other words, it induces a supermartingale when we have

$$\begin{align}
-\frac{1}{2} G_t \cdot\kappa(G_t) f'(G_t)+2f''(G_t)+c \cdot f(G_t)\leq 0.\notag
\end{align}$$


It implies that a proper $f$ may help us obtain the desired result

$$\begin{align}
  \mathrm{E}[f(\|X_t-Y_t\|)] \leq f(\|X_0-Y_0\|)\cdot \exp(-c\cdot t).\notag
\end{align}$$



### How to build such an $f$

#### A simple case when $c = 0$

We propose to find a $f$ that satisfies 

$$\begin{align}
f''(G_t)\leq \frac{1}{4} G_t \cdot\kappa(G_t) f'(G_t).\notag
\end{align}$$

The worst case is given by $f(R)=\int_0^{R} f'(s) \mathrm{d}s$, where $f'$ is solved by Growall inequality

$$\begin{align}
f'(R)&=\exp\bigg\{\int_0^R\frac{1}{4} s \cdot\kappa(G_t) \mathrm{d}s\bigg\}.\notag
\end{align}$$

#### Extention to $c>0$

We aim to obtain the following dimension-independent bound in $R, L\in [0, \infty)$ {% cite reflection_coupling %}.

The general idea is to permit strong convexity outside of a ball with a given radius, within which local non-convexity is allowed.

$-\mathbb{I}\_{[\\|X_t-Y_t\\|< R]} L{\\|X_t-Y_t\\|^2}\leq \langle U(X_t)-U(Y_t), X_t-Y_t\rangle \leq \mathbb{I}\_{[\\|X_t-Y_t\\|\geq R]} K{\\|X_t-Y_t\\|^2}.$]]></content><author><name>Wei Deng</name></author><category term="Coupling" /><summary type="html"><![CDATA[Limitations of Synchronous Coupling]]></summary></entry><entry><title type="html">Girsanov and MLE</title><link href="http://localhost:4000/posts/Girsanov_MLE/" rel="alternate" type="text/html" title="Girsanov and MLE" /><published>2023-03-20T00:00:00-07:00</published><updated>2023-03-20T00:00:00-07:00</updated><id>http://localhost:4000/posts/Girsanov-Likelihood</id><content type="html" xml:base="http://localhost:4000/posts/Girsanov_MLE/"><![CDATA[### Maximum likelihood estimation

Given $N$ independent observations, the likelihood function given $\theta=(\mu, \sigma)$ follows that

$$\begin{align}
\mathcal{L}(\{x_i\}_{i=1}^N|\theta)=\prod_{i=1}^N f(x_i|\theta),\notag
\end{align}$$

which models the density of the random variable $X$. The maximum likelihood estimator (MLE) is given by

$$\begin{align}
\widehat\theta=\text{argmax} \mathcal{L}(\mathbf{x}|\theta),\notag
\end{align}$$

where $\mathbf{x}=\\{x_i\\}_{i=1}^N$. When $X$ is a Gaussian random variable that follows $X\sim \mathcal{N}(\mu, \sigma^2)$. The likelihood function is expressed as

$$\begin{align}\label{MLE}
\mathcal{L}(\{x_i\}_{i=1}^N|\theta)=\bigg(\frac{1}{\sqrt{2\pi \sigma^2}}\bigg)^{N/2} \exp\bigg(-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}\bigg).
\end{align}$$

Taking the gradient w.r.t. $\mu$ and $\sigma^2$, we have

$$\begin{align}
\widehat \mu=\frac{1}{N}\sum_{i=1}^N x_i, \quad \widehat\sigma^2=\frac{1}{N} \sum_{i=1}^N (x_i-\widehat \mu)^2.\notag
\end{align}$$


### Girsanov theorem

Assume we have a diffusion process

$$\begin{align}
\mathrm{d}X_t = b(X_t;\theta)\mathrm{d}t+\sigma\mathrm{d}W_t.\notag
\end{align}$$

We observe the whole path of the process $X\_t$ from time $[0, T]$. Denote by $\mathbb{P}\_X$ the law of the process on the path space, which is absolutely continuous w.r.t. the Wiener measure. The density of $\mathbb{P}\_X$ w.r.t. the Wiener measure is determined by the Radon-Nikodym derivative 

$$\begin{align}\label{girsanov}
\frac{\mathrm{d}\mathbb{P}_X}{\mathrm{d}\mathbb{P}_W}=\exp\bigg(\frac{1}{\sigma}\int_0^T b(X_s; \theta)\mathrm{d}W_s-\int_0^T \frac{b^2(X_s;\theta)}{2\sigma^2}\mathrm{d}s \bigg).
\end{align}$$




We can observe a close connection between Eq.\eqref{MLE} and a discrete variant of Eq.\eqref{girsanov} 

Remark: While the Girsanov theorem is commonly employed, it is prone to mistakes that can be easily made. Have I made any such errors?


### Applications

Given a stationary Ornstein-Uhlenbeck process, how do you estimate the parameters using MLE {% cite Grigorios_14 %}..

$$\begin{align}
\mathrm{d}X_t = -\alpha X_t \mathrm{d}t+\sigma\mathrm{d}W_t.\notag
\end{align}$$

Hint: 1) write the likelihood; 2) take the gradient.]]></content><author><name>Wei Deng</name></author><summary type="html"><![CDATA[Maximum likelihood estimation]]></summary></entry><entry><title type="html">Schrödinger Bridge Problem</title><link href="http://localhost:4000/posts/Bridge/" rel="alternate" type="text/html" title="Schrödinger Bridge Problem" /><published>2022-06-19T00:00:00-07:00</published><updated>2022-06-19T00:00:00-07:00</updated><id>http://localhost:4000/posts/Bridges</id><content type="html" xml:base="http://localhost:4000/posts/Bridge/"><![CDATA[The classical Schrödinger Bridge Problem (SBP) have found interesting applications in deep generative models {% cite Nea11 %}, {% cite forward_backward_SDE %}, {% cite DSB %} and financial mathematics {% cite nutz_trading %} {% cite nutz_portfolio %} {% cite schrodinger_vol_model %}. The iterative nature in solving this problem shows a great potential to further accelerate the training for score-based generative models, although the later is already the state-of-the-art methods [\[Image Generation\]](https://paperswithcode.com/sota/image-generation-on-cifar-10).

The most striking feature of this algorithm is its deep mathematical connections to stochastic optimal control, optimal transport, fluid dynamics {% cite siam_review_Sinkhorn_liaisons %}, and DNN approximations. As such, we have sufficient tools to understand the underlying theories. We refer interested readers to the Appendix A of {% cite provably_schrodinger_bridge %}.]]></content><author><name>Wei Deng</name></author><category term="Diffusion Model" /><summary type="html"><![CDATA[The classical Schrödinger Bridge Problem (SBP) have found interesting applications in deep generative models (Neal, 2011), (Chen et al., 2022), (De Bortoli et al., 2021) and financial mathematics (Nutz, 2022) (Nutz, 2022) (Henry-Labordere, 2019). The iterative nature in solving this problem shows a great potential to further accelerate the training for score-based generative models, although the later is already the state-of-the-art methods [Image Generation].]]></summary></entry><entry><title type="html">Hamiltonian Monte Caro</title><link href="http://localhost:4000/posts/Hamiltonian/" rel="alternate" type="text/html" title="Hamiltonian Monte Caro" /><published>2021-11-01T00:00:00-07:00</published><updated>2021-11-01T00:00:00-07:00</updated><id>http://localhost:4000/posts/Hamiltonian</id><content type="html" xml:base="http://localhost:4000/posts/Hamiltonian/"><![CDATA[Hamiltonian Monte Carlo {% cite Nea11 %} (HMC) is a popular Markov chain Monte Carlo (MCMC) algorithm to simulate from a probability distribution and is believed to be faster than the Metropolis Hasting algorithm {% cite MRRT53 %} and Langevin dynamics. However, the convergence properties are far less understood compared to its empirical successes. 

In this blog, I will introduce a paper called Optimal Convergence Rate of Hamiltonian Monte Carlo for Strongly Logconcave Distributions {% cite CV19 %}. 

## Hamiltonian Dynamics

HMC algorithms conserves Hamiltonian and the volume in the phase space and enjoy the reversibility condition (by flipping a sign). It aims to simulate particles according to the laws of Hamiltonian dynamics. Consider a Hamiltonian function $H(x, v)$ defined as follows

\begin{equation}\notag
H(x, v)=f(x)+\\|v\\|^2,
\end{equation}

where $f$ is the potential energy function, $x$ is the position, and $v$ is the velocity variable. In each step, the update of the particles $(x, v)$ follows the system of (ordinary) differential equations as follows


\begin{equation}\label{hmc_eq}
\frac{d x}{d t}=\frac{\partial H}{\partial v}=v(t) \ \ \text{and} \ \ \frac{d v}{d t}=-\frac{\partial H}{\partial x}=-\nabla f(x).
\end{equation}

After a time interval $t$, the solutions follow a ``Hamiltonian flow'' $\varphi_t$ that maps $(x,v)$ to $(x_t(x,v), v_t(x, v))$.





## Convergence of Ideal HMC

To prove the convergence of the ideal HMC algorithms, we first assume standard assumptions.

**Strong convexity** We say $f$ is $\mu$-strongly convex if for all $x, y\in R^d$, we have

\begin{equation}\notag
f(y)\geq f(x)+\langle \nabla f(x), y-x\rangle + \frac{\mu}{2} \\|y-x\\|^2.
\end{equation}

**Smoothness** We also assume $f$ is $L$-smooth in the sense that

\begin{equation}\notag
f(y)\leq f(x)+\langle \nabla f(x), y-x\rangle + \frac{L}{2} \\|y-x\\|^2.
\end{equation}

The convergence analysis hinges on the coupling of two Markov chains such that the distance between the position variables $x_k$ and $y_k$ (the second Markov chain) contracts in each step.

Denote by $x(t)$ and $y(t)$ solutions of HMC (\ref{hmc_eq}) and denote by $x(0)$ and $y(0)$ the initial positions of two ODEs for HMC. To faciliate the analysis of coupling techniques, we adopt the same initial velocity $v(0)=u(0)$. The convergence study hinges on the contraction bound as follows

<p align="center">
    <img src="/images/HMC_coupling2.png" width="400" />
</p>


**Lemma** Assume the potential function $f$ satisfies the convexity and smoothness assumptions. Then for $0\leq t \leq \frac{1}{2\sqrt{L}}$, we have

\begin{equation}\notag
\\|x(t)-y(t)\\|^2 \leq (1-\frac{\mu}{4}t^2) \\|x(0)-y(0)\\|^2.
\end{equation}


**Proof**
Consider two ODEs for HMCs: 

$$\begin{align}\notag
\qquad\qquad\qquad\qquad x'(t)&=v(t)    \qquad\qquad \quad\text{and}\qquad y'(t)=u(t) \notag\\\\
\qquad\qquad\qquad\qquad v'(t)&=-\nabla f(x(t))     \quad\qquad\qquad\ \   u'(t)=-\nabla f(y(t)),\notag
\end{align}$$

where the initial velocities follow $u(0)=v(0)$. 

Taking the second derivative of $\frac{1}{2}\\|x-y\\|^2$, we have

$$\begin{align}\notag
\frac{d^2}{dt^2}\left(\frac{1}{2} \|x-y\|^2\right)&=\frac{d}{dt}\langle v-u, x-y \rangle\notag\\
						  &=\langle v'-u', x-y \rangle + \langle v-u, x'-y' \rangle \notag\\
						  &=-\rho \|x-y\|^2 + \|v-u\|^2,\notag
\end{align}$$

where $\rho=\rho(t)=\frac{\langle \nabla f(x) - \nabla f(y), x-y \rangle}{\\|x-y\\|^2}$.

To upper bound $\\|v-u\\|^2$, recall that 
\begin{equation}\notag
\frac{d}{dt} \\|x\\|=\frac{d}{dx} \\|x\\| \cdot \frac{d}{dt} x=\frac{\langle x, \dot{x} \rangle}{\\|x\\|}.
\end{equation}

In what follows, we have

\begin{equation}\notag
\frac{d}{dt}\\|v-u\\|=\frac{1}{\\|v-u\\|}\langle v'-u', v-u\rangle =-\frac{\langle \nabla f(x)-\nabla f(y), v-u\rangle}{\\|v-u\\|}.
\end{equation}

In particular for the upper bound of $\frac{d}{dt}\\|v-u\\|$, we have

$$\begin{align}
\left|\frac{d}{dt}\|v-u\|\right| &\leq \|\nabla f(x)-\nabla f(y)\| \notag\\
                                 & \leq \sqrt{L \langle \nabla f(x) - \nabla f(y), x-y \rangle} \notag\\
                                 & = \sqrt{L\rho \|x-y\|^2} \notag\\
				 & \leq \sqrt{2L\rho \|x_0-y_0\|^2}, \notag\\
\end{align}$$

where the first inequality follows by Cauchy–Schwarz inequality, the second inequality follows by the L-smoothness assumption, and the last inequality follows by Claim 7 in {% cite CV19 %}.

Now, we can upper bound $\\|v-u\\|^2$ as follows

$$\begin{align}
\|v-u\|^2 &\leq  \left(\int_0^t \left|\frac{d}{ds}\|v-u\|\right| ds\right)^2 \notag\\
\qquad\qquad & \leq \left(\int_0^t \sqrt{2 L\rho} \|x_0-y_0\| ds\right)^2 \notag\\
\qquad\qquad & \leq 2L t \left(\int_0^t \rho ds\right) \|x_0 - y_0\|^2. \notag\\
\end{align}$$

Define the monotone increasing function

\begin{equation}\notag
P=P(t)=\int_0^t \rho dt,
\end{equation}

where $P(0)=0$ and $\mu t \leq P(t)\leq L t$ for all $t\geq 0$. Then

\begin{equation}\notag
\|v-u\|^2 \leq 2L t P\|x_0-y_0\|^2.
\end{equation}

Combining the above upper bounds, we have

\begin{equation}\notag
\frac{d^2}{dt^2} \left(\frac{1}{2}\\|x-y\\|^2 \right)\leq -\rho \left(\frac{1}{2} \\|x_0-y_0\\|^2\right)+2Lt P \\|x_0-y_0\\|^2.
\end{equation}

Define $\alpha(t)=\frac{1}{2} \\|x-y\\|^2$, then we have

\begin{equation}\notag
\alpha'(t)\leq -\alpha(0) (\rho(t)-4L t P(t)).
\end{equation}

Integrating both sides and combining the fact that $\alpha'(0)=0$, we have

$$\begin{align}
\alpha'(t)&=\int_0^t \alpha'(s) ds \notag\\
\qquad\ &\leq -\int_0^t \alpha(0) (\rho(s)-4L t P(s))ds \notag\\
\qquad\ &\leq -\alpha(t)\left(P(t) - 4LP(t) \int_0^t s ds\right) \notag\\
\qquad\ &=-\alpha(0)P(t)(1-2Lt^2). \notag
\end{align}$$

Choose $t \in [0, \frac{1}{2\sqrt{L}}]$, then we can deduce that
\begin{equation}\notag
\alpha'(t)\leq -\alpha(0) \frac{\mu}{2} t.
\end{equation}

Eventually, we have the desired result such that

\begin{equation}\notag
\alpha(t)=\alpha(0)+\int_0^t \alpha'(s) d s \leq \alpha(0) \left(1-\frac{\mu}{4} t^2\right).
\end{equation}


Setting $t=T=1/(c\sqrt{L})$ for some constant $c\geq 2$, we get

\begin{equation}\notag
\|x(T)-y(T)\|^2 \leq \left(1-\frac{1}{4c^2 \kappa}\right)\|x(0)-y(0)\|^2.
\end{equation}

Eventually, we can achieve the convergence in Wasserstein distance such that 

\begin{equation}\notag
W^2_2(\nu_k, \pi)\leq E\left[\|x_k-y_k\|^2\right]\leq \left(1-\frac{1}{4c^2 \kappa}\right)^k O(1).
\end{equation}

## Discretized HMC

{% cite MV18 %} proposed to approximate the Hamiltonian trajectory with a second-order Euler integrator such that

\begin{equation}\notag
\hat{x_{\eta}}(x, v)=x+v \eta - \frac{1}{2} \nabla f(x), \quad \hat{v_{\eta}}(x, v)=v-\eta \nabla f(x) - \frac{1}{2} \eta^2 \nabla^2 f(x) v.
\end{equation}

Since Hessian is expensive to computate and store, an approximation is conducted through

\begin{equation}\notag
\nabla^2 f(x) v \approx \frac{\nabla f(\hat{x_{\eta}}) - \nabla f(x)}{\eta},
\end{equation}

Now, the numerical integrator follows that

\begin{equation}\notag
\hat{x_{\eta}}(x, v)=x+v \eta - \frac{1}{2} \nabla f(x), \qquad \hat{v_{\eta}}(x, v)=v-\frac{1}{2}\eta (\nabla f(x) - \nabla f(\hat{x_{\eta}})).
\end{equation}

It can be shown that such a discretized HMC requires O($d^{\frac{1}{4}} \epsilon^{-\frac{1}{2}}$) gradient evaluations under proper regularity assumptions {% cite MV18 %}. Other interesting persepectives can be seen in {% cite Che20 %}.



## Conclusions

Properly tuning the number of leapfrog steps is important for maximizing the contraction to accelerate convergence. From the perspective of methodology, the no-U-turn sampler proposes to automatically adjust the number of leapfrog steps and potentially exploits this idea by checking the inner product of postion and velocity {% cite HG14 %}.]]></content><author><name>Wei Deng</name></author><category term="Monte Carlo Methods" /><summary type="html"><![CDATA[Hamiltonian Monte Carlo (Neal, 2011) (HMC) is a popular Markov chain Monte Carlo (MCMC) algorithm to simulate from a probability distribution and is believed to be faster than the Metropolis Hasting algorithm (Metropolis, 1953) and Langevin dynamics. However, the convergence properties are far less understood compared to its empirical successes.]]></summary></entry><entry><title type="html">Couplings and Monte Carlo Methods (I)</title><link href="http://localhost:4000/posts/Couplings/" rel="alternate" type="text/html" title="Couplings and Monte Carlo Methods (I)" /><published>2021-08-01T00:00:00-07:00</published><updated>2021-08-01T00:00:00-07:00</updated><id>http://localhost:4000/posts/Coupling</id><content type="html" xml:base="http://localhost:4000/posts/Couplings/"><![CDATA[A coupling of two random variables/ vectors represents a joint distribution, where the marginal distributions are denoted by $p$ and $q$, respectively. Any joint distributions of $p$ and $q$ define a valid coupling. Although there are infinitely many of them, some of them are quite special and may facilitate our analysis. 


# Maximal Coupling

Total variation distance is defined as follows

\begin{equation}\notag
\forall A\in X, \quad \|p-q\|\_{\text{TV}}=\sup\_{X\in A} \mathbb{P}(X\in A) - \mathbb{P}(Y\in A),
\end{equation}
where $X$ and $Y$ are random variables defined on the state space $\mathbb{X}$ with measurable set $X$. Note that for any measurable set $A\in X$, the follow inequality always holds

$\mathbb{P}(X\in A)- \mathbb{P}(Y\in A)=\mathbb{P}(X\in A \cap X\neq Y)- \mathbb{P}(Y\in A \cap X\neq Y)\leq \mathbb{P}(X\neq Y)$.

There exists one pair of $(X,Y)$ such that the above inequality holds. Any coupling that satisfies this property is known as **maximal coupling**.

Denoting by $\nu=p-q$ the zero-mass measure, there is a set $D$ according to the Hahn-Jordan decomposition such that $\nu^{+}=(p-q)(\cdot \cap D)$ and $\nu^{-}=(q-p)(\cdot \cap D^c)$ are both positive measures and $\nu=\nu^{+}-\nu^-$.


Notably, it is clear that $D=\\{x:\ p(x)\geq q(x)\\}$. It follows that $\sup_{A\in {X}} \mathbb{P}(X\in A)- \mathbb{P}(Y\in A)=\sup_{A\in {X}}\nu(A)=\nu(D)=\mathbb{P}(X\in D)-\mathbb{P}(Y\in D)$. We have

$$\begin{align}
\mathbb{P}(X\in D)-\mathbb{P}(Y\in D)&=\int_{\{x:\ p(x)\geq q(x)\}} p(x) d x - \int_{\{x:\ p(x) \geq q(x)\}} q(x) d x\nonumber\\
&=\int_{\{x:\ p(x)< q(x)\}} q(x) d x - \int_{\{x:\ p(x) < q(x)\}} p(x) d x.\nonumber
\end{align}$$

<p align="center">
    <img src="/images/TS_distance.png" width="600" />
</p>
Summing up the above equations and combining $|a-b|=a+b-2 a\wedge b$, we can obtain the area between the two pdf curves {% cite Jacob_Pierre %}

\begin{equation}\notag
\|p-q\|_{\text{TV}}=\frac{1}{2} \int |p(x)- q(x)| d x = 1-\int \min \\{p(x), q(x) \\} dx.
\end{equation}
 
In the end, we can summarize the different formulations of total variation
$$\begin{align}\notag
\|p-q\|_{\text{TV}}&=\sup \mathbb{P}(X\in A)- \mathbb{P}(Y\in A)\\
		   &=\frac{1}{2}\int |p(x)- q(x)| d x\notag\\
		   &=1-\int \min\{p(x), q(x)\} d x\notag\\
		   &=\inf_{(X,Y)\in \text{coupling}(p, q)} \mathbb{P}(X\neq Y).\notag
\end{align}$$


### Applications

Suppose $(X_i)$ follow an (independent) binomial distribution $Binomial(\lambda, N)$ and $(Y_i)$ follow an (independent) Poisson distribution $Poisson(\lambda)$. Next, we couple $X_i$ and $Y_i$ maximally. The **overlap mass** is equal to $(1-\lambda)\wedge e^{-\lambda} + \lambda \wedge \lambda e^{-\lambda}=1-\lambda+\lambda e^{-\lambda}$. That means $\mathbb{P}(X_i\neq Y_i)=\lambda(1-e^{-\lambda})\leq \lambda^2$.

Replace $\lambda$ with $\lambda/N$, we have
\begin{equation}\notag
\mathbb{P}\left(\frac{\sum_{i=1}^N X_i-\sum_{i=1}^N Y_i}{N}\right)\leq \frac{\lambda^2}{N},
\end{equation}
where implies that given a large N and a fixed $\lambda$, Poisson distribution approximates the binomial distribution.

### Convergence rates

By assuming $(Y_t)$ is simulated from the stationary distribution in the beginning, we can introduce a coupling inequality such that

\begin{equation}\notag
{L}(X_t)-{L}(Y_t)\| \leq \mathbb{P}(\tau>t),
\end{equation}
where $\tau$ is a random variable that enables $X_t=Y_t$ and is also known as ''meeting time''. The equality can be achieved given the maximal coupling but the contruction may differ in different problems. In addition, meeting exactly sometimes is quite restricted; it is enough to consider close enough chains.

# Synchronous Coupling

Synchronous coupling models the contraction of a pair of trajectories and can be used to prove the convergence of stochastic gradient Langevin dynamics for strongly log-concave distributions.

Let $\theta_k\in \mathbb{R}^d$ be the $k$-th iterate of the following stochastic gradient Langevin algorithm.
\begin{align}\notag
    \theta_{k+1}=\theta_k -\eta \nabla \widetilde f(\theta_k)+\sqrt{2\tau\eta}\xi_k,
\end{align}
where $\eta$ is the learning rate, $\tau$ is the temperature, $\xi_k$ is a standard $d$-dimensional Gaussian vector, and $\nabla \widetilde f(\theta)$ is an unbiased estimate of the exact gradient $\nabla f(\theta)$.




## Assumptions

**Smoothness** We say $f$ is $L$-smooth if for some $L>0$
\begin{align}\label{def:strong_convex}
f(y)\leq f(x)+\langle \nabla f(x),y-x \rangle+\frac{L}{2}\\| y-x \\|^2_2\quad \forall x, y\in \mathbb{R}^d.
\end{align}


**Strong convexity**
We say $f$ is $m$-strongly convex if for some $m>0$
\begin{align}\label{def:smooth}
f(x)\geq f(y)+\langle \nabla f(y),x-y \rangle + \frac{m}{2} \\| y-x \\|_2^2\quad \forall x, y\in \mathbb{R}^d.
\end{align}


**Bounded variance** The variance of stochastic gradient $\nabla \widetilde f(x)$ is upper bounded such that
\begin{align}\label{def:variance}
\mathbb{E}[\\|\nabla \widetilde f(x)-\nabla f(x)\\|^2] \leq \sigma^2 d,\quad \forall x\in \mathbb{R}^d.
\end{align}




## A Crude Estimate

Assume assumptions \ref{def:strong_convex}, \ref{def:smooth}, and \ref{def:variance} hold. For any learning rate $\eta \in (0 , 1 \wedge {m}/{L^2} )$  and $\|\| \theta_0-\theta_* \|\| \leq \sqrt{d} {D}$, where $\theta_*$ is a stationary point. Then


\begin{align}\notag
W_2(\mu_k, \pi) \leq e^{-{mk\eta}/{2}} \cdot 2 ( \sqrt{d} {D} + \sqrt{d/m} ) + \sqrt{ 2d (\sigma^2+L^2 G\eta) / m^2},
\end{align}

where $\mu_k$ denotes the probability measure of $\theta_k$ and $G:=25(\tau+m {D}^2+\sigma^2)$.


## Proof
Denote $\theta_t$ as the continuous-time interpolation of the stochastic gradient Langevin dynamics as follows

\begin{align}\notag
d \theta_t = - \nabla \widetilde f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) d t + \sqrt{2\tau} d \widetilde W_t,
\end{align}

where ${\theta}_0=\theta_0$. For any $k\in \mathbb{N}^{+}$ and a time $t$ that satisfies $t=k\eta$, it is apparent that $\widehat\mu_t={L}({\theta}_t)$ is the same as $\mu_k={L}(\theta_k)$, where ${L}(\cdot)$ denotes a distribution of a random variable. In addition, we define an auxiliary process $(\beta_t)$ that starts from the stationary distribution $\pi$

\begin{align}\notag
d \beta_t = - \nabla f(\beta_t) d t + \sqrt{2\tau} d W_t.
\end{align}



Consider Itô's formula for the sequence of $\frac{1}{2}  \\| \theta_t - \beta_t \\| ^2$

$$\begin{align}\notag
&\ \ \ \frac{1}{2} d  \| \theta_t - \beta_t \|^2\notag\\
&= \langle \theta_t - \beta_t, d \theta_t - d \beta_t \rangle + \mathrm{Tr}[ d^2 \theta_t - d^2 \beta_t ]\notag\\
&=\langle \theta_t - \beta_t, (\nabla f(\beta_t) -\nabla\widetilde  f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) ) d t + \sqrt{2\tau} ( d \widetilde W_t - d W_t ) \rangle + 2\tau \mathrm{Tr}[ d^2 \widetilde W_t - d^2 W_t ].\notag
\end{align}$$


Taking $\widetilde W_t=W_t$ defines a synchronous coupling. Arrange the terms

$$\begin{align}\notag
&\ \ \ \frac{1}{2} d \| \theta_t - \beta_t \|^2 \notag\\
&= \langle \theta_t - \beta_t, \nabla f(\beta_t)-\nabla f(\theta_t) \rangle d t+ \langle \theta_t - \beta_t,  \nabla f(\theta_{t}) - \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor})  \rangle d t\notag\\
&\qquad \qquad\qquad+ \langle \theta_t - \beta_t, \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) - \nabla \widetilde f(\widehat \theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) \rangle d t \notag\\
&\leq - m \| \theta_t - \beta_t \|^2 d t + \frac{m}{4} \| \theta_t - \beta_t \|^2 d t + \frac{1}{m}  \| \nabla f(\theta_{t}) - \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor})  \|^2 d t \notag\\
&\qquad\qquad  + \frac{m}{4} \| \theta_t - \beta_t \|\|^2 d t + \frac{1}{m} \| \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) - \nabla \widetilde f(\widehat \theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) \|^2 d t\notag\\
&\leq  - \frac{m}{2} \| \theta_t - \beta_t \|\|^2 d t + \frac{d\sigma^2}{m} d t +\frac{1}{m} \| \nabla f(\theta_{t}) - \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) \|^2  d t\notag\\
&\leq  - \frac{m}{2} \| \theta_t - \beta_t \|^2 d t + \frac{d\sigma^2}{m} d t+ \frac{L^2}{m} \| \theta_{t} - \theta_{\eta\lfloor\frac{t}{\eta} \rfloor} \|^2  d t\notag\\
\end{align}$$


where the first inequality follows from $ab\leq  (\frac{\sqrt{m}}{2}a)^2+({\frac{1}{\sqrt{m}}}b)^2$ and the strong-convexity property \ref{def:strong_convex}; in particular, we don't attempt to optimize the constants of $-\frac{m}{2}$ for the item $\|\| \theta_t - \beta_t \|\|^2$; the second and third inequalities follow by bounded variance assumption \ref{def:variance} and the smoothness assumption \ref{def:smooth}, respectively.


Now apply Grönwall's inequality to the preceding inequality and take expectation respect to a coupling $(\theta_t, \beta_t) \sim \Gamma(\widehat\mu_t,\pi)$
\begin{align}\label{eq:1st_gronwall}
     \mathbb{E}{ \\|\theta_t - \beta_t \\|^2}\leq  \mathbb{E}{\\| \theta_0 - \beta_0 \\|^2} e^{-mt}+\frac{2}{m}\int_0^t g(d\sigma^2+ L^2\underbrace{\mathbb{E}{ \\| \theta_{s} - \theta_{\eta\lfloor\frac{s}{\eta} \rfloor} \\|^2 }}_{I: \text{Discretization error}} g) e^{-(t-s)m} d s. 
\end{align}


Plugging some estimate of $I$ into Eq.\eqref{eq:1st_gronwall}, we have
$$\begin{align}\notag
&\ \ \ \mathbb{E}{ \| \theta_t - \beta_t \|^2 }\\
&\leq  \mathbb{E}{ \| \theta_0 - \beta_0 \|^2} e^{-mt}+\frac{2d}{m} (\sigma^2+L^2 G\eta) \int_0^t  e^{-(t-s)m} d s\notag\\
&\leq \mathbb{E}{ \| \theta_0 - \beta_0 \|^2} e^{-mt}+\frac{2d}{m^2} (\sigma^2+L^2 G\eta).\notag
\end{align}$$


Recall that $\theta_k$ and $\widehat\theta_{t\eta}$ have the same distribution $\mu_k$. By the definition of $W_2$ distance, we have

$$\begin{align}\notag
&\ \ \ W_2(\mu_k, \pi)\\
&\leq e^{-{mk\eta}/{2}} \cdot W_2(\mu_0, \pi) + \sqrt{ 2d (\sigma^2+L^2 G\eta) / m^2}\notag\\
&\leq e^{-{mk\eta}/{2}} \cdot 2 (\| \theta_0 - \theta_* \| +  \sqrt{d/m} )+ \sqrt{ 2d(\sigma^2+L^2 G\eta) / m^2}\notag\\
&\leq e^{-{mk\eta}/{2}} \cdot 2 ( \sqrt{d} {D} +  \sqrt{d/m} )+  \sqrt{ 2 d(\sigma^2+L^2 G\eta) / m^2},\notag
\end{align}$$

where the first inequality follows by applying $\sqrt{\| a + b \|} \leq \sqrt{\| a \|} + \sqrt{\| b \|}$, the second one follows by an estimate of $W_2(\mu_0, \pi)$, and the last step follows from the initialization condition.

### Remark: How to achieve a sharper upper bound?]]></content><author><name>Wei Deng</name></author><category term="Coupling" /><summary type="html"><![CDATA[A coupling of two random variables/ vectors represents a joint distribution, where the marginal distributions are denoted by $p$ and $q$, respectively. Any joint distributions of $p$ and $q$ define a valid coupling. Although there are infinitely many of them, some of them are quite special and may facilitate our analysis.]]></summary></entry><entry><title type="html">The Lyapunov Function Method for Poincaré Inequality</title><link href="http://localhost:4000/posts/Lyapunov_Poincare/" rel="alternate" type="text/html" title="The Lyapunov Function Method for Poincaré Inequality" /><published>2021-06-01T00:00:00-07:00</published><updated>2021-06-01T00:00:00-07:00</updated><id>http://localhost:4000/posts/Lyapunov-Poincare</id><content type="html" xml:base="http://localhost:4000/posts/Lyapunov_Poincare/"><![CDATA[Poincaré (spectral gap) inequality {% cite Bakry08 %} is the first important family of functional inequalities that charaterizes the exponential convergence of a random variable towards the equilibrium.


## Langevin diffusion

Suppose we are interested in the convergence of the stochastic differential equation

\begin{equation}\notag
dx_t = -\nabla U(x_t)dt + \sqrt{2}dW_t,
\end{equation}

where $\nabla U(\cdot)$ denotes the gradient of a energy function $U$ and $(W_t)_{t\geq 0}$ is a Brownian motion. Under mild growth conditions on $U(\cdot)$, $x$ converges to a stationary measure $\mu(x)\propto e^{-U(x)}$.


Define a family of operators $(P_t)_{t\geq 0}$ as follows

\begin{equation}\notag
P_t(f(x)) = E[f(x_t)\|$=x],
\end{equation}
where the expectation is taken over a particular set to denote the conditional density.

For a smooth test function $f(x)$, Itô's formula implies that

\begin{equation}\notag
d f(x_t) = \sqrt{2} \nabla f(x_t) dB_t + Lf(x_t)dt,
\end{equation}
where $L$ is the infinitesimal generator of the symmetric Markov Semigroup $P_t$ 

\begin{equation}\notag
Lf=\lim_{t\rightarrow 0} \frac{P_t f -f }{t}=\Delta f - \langle\nabla U, \nabla f\rangle,
\end{equation}
where $\Delta$ denotes the Laplace operator.

## Poincaré Inequality

We say the Gibbs measure $\mu$ satisfies a Poincaré equality with a constant $C$ if

\begin{equation}\notag
Var_{\mu}(f)=\int f^2 d\mu -(\int f d\mu)^2 \leq C \xi(f),
\end{equation}
where $\xi$ is the Dirichlet form defined as 

\begin{equation}\notag
\xi(f)=\int \Gamma(f)d\mu.
\end{equation}

$\Gamma$ is the Carré du Champ operator satisfying 

\begin{equation}\notag
\Gamma(f)=\frac{1}{2}(L(f^2)-2 f L(f)). 
\end{equation}
Since $\mu$ is reversible for $P_t$, we have the invariance property $\int L(f)=0$ for all f in the Dirichlet domain. In other words, for symmetric $\mu$, we have 

\begin{equation}\notag
\xi(f)=\int \Gamma(f)d\mu=-\int f L(f) d\mu =\int (\nabla f)^2 d\mu.
\end{equation}
where the last inequality follows by integration by parts such that: $-\int f L(f) d\mu=-\int f\nabla (e^{-U(x)}\nabla f)dx=-\int f d(e^{-U(x)} \nabla f)=f e^{-U(x)} \nabla f\|_{boundary} + \int (\nabla f)^2 d\mu.$

## Variance Decay

Now we study the decay of variance

\begin{equation}\notag
\Lambda(t)=Var_{\mu}(P_t f)= \int(P_t f)^2d\mu.
\end{equation}
Reacll $\xi(f)=-\int f L(f) d\mu$. Taking the derivative

\begin{equation}\notag
\Lambda_t(t)=2\int P_t f L P_t f d\mu = -2 \xi(P_t f).
\end{equation}

Combining the Poincaré equality, we have that

\begin{equation}\notag
\Lambda(t)=Var_{\mu}(P_t f)\leq C \xi(P_t f)=-\frac{C}{2}\Lambda_t(t)
\end{equation}
This means that $\Lambda_t(t)\leq -\frac{2}{C} \Lambda(t)$. Including an integration factor $e^{\frac{2t}{C}}$, we have

\begin{equation}\notag
\nabla (\Lambda(t) e^{\frac{2t}{C}})=\Lambda_t(t) e^{\frac{2t}{C}} + \Lambda(t) \frac{2}{C} e^{\frac{2t}{C}}\leq 0.
\end{equation}
Hence $\Lambda(t) e^{\frac{2t}{C}} \leq \Lambda(0)$. In other words,

\begin{equation}\notag
Var_{\mu}(P_t f)\leq e^{-2t/C} Var_{\mu}(f).
\end{equation}

## How to identify the Poincaré constant

Despite the appealing formulation, identifying the best constant $C>0$ is in general not easy. In this blog, we will show a method for determining a crude estimate of such a constant.

We denote a Lyapunov function by $V$ if $V\geq 1$ and if there exist $\lambda>0, b\geq 0$ and some $R > 0$ such that for all $x$, the following drift condition holds

\begin{equation}\notag
LV(x) ≤ -\lambda V(x) + b 1_{B(0, R)}(x).
\end{equation}

### By Theorem 1.4 [1], we show that if there exists a Lyapunov function $V(x)$ satisfying the drift condition, then $\mu $ satisfies a $L^2$ Poincaré inequality with constant $C_P=\frac{1}{\lambda}(1+b\kappa_R)$, where $\kappa_R$ is the L2 Poincaré constant of $\mu$ restricted to the ball B(0,R).



Given a smooth function $g$, we know that $Var_{\{\mu}}(g)\leq \int (g-c)^2 d\mu$ for all $c$. In what follows, we set $f=g-c$, where $c$ is a constant to be selected later.

Next, we reformulate the drift condition and take an integral for $f^2$ with respect to $\mu$:

\begin{equation}\notag
\int f^2 d\mu \leq \int \frac{-LV}{\lambda V} f^2 d\mu + \int f^2 \frac{b}{\lambda V}1_{B(0, R)}d \mu.
\end{equation}

### Control the first term $\int \frac{-LV}{\lambda V} f^2 d\mu$

Since $L$ is $\mu$-symmetric, by integration by parts, we get

$\int \frac{-LV}{V}f^2d \mu= \int \nabla\left(\frac{f^2}{V}\right) \nabla V d\mu$

$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  =2\int \frac{f}{V} \nabla f \nabla V d\mu  - \int \frac{f^2}{V^2} \|\nabla V\|^2 d\mu$

$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ =\int \|\nabla f\|^2 d\mu - \int \|\nabla f - \frac{f}{V} \nabla V\|^2 d\mu$

$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \leq \int \|\nabla f\|^2 d\mu$

### Control the second term $\int f^2 \frac{b}{\lambda V}1_{B(0, R)} d\mu$

Since $\mu$ satisfies a Poincaré inequality on $B(0, R)$ with a constant $\kappa_R$, we have

\begin{equation}\notag
\int_{B(0, R)} f^2 d\mu\leq \kappa_R \int_{B(0, R)} \|\nabla f\|^2 d\mu + (1/\mu(B(0, R))) \left(\int_{B(0, R)} fd\mu\right)^2.
\end{equation}

Fix $c=\int_{B(0, R)} gd\mu$. We have
\begin{equation}\notag
\int_{B(0, R)} \frac{f^2}{V}d\mu\leq \int_{B(0, R)} f^2 d\mu\leq \kappa_{R}\int_{B(0, R)} \|\nabla f\|^2d\mu.
\end{equation}
Eventually, we have

\begin{equation}\notag
Var_{\mu}(f)=\int f^2 d\mu \leq \frac{1}{\lambda} (1+b\kappa_R) \int \|\nabla f\|^2 d\mu.
\end{equation}
In other words, the Poincaré inequality has a crude constant $C_p=\frac{1}{\lambda} (1+b \kappa_R)$.

## Construction of the Lypunov function

Suppose we require one tail condition of the energy function $U(x)$, i.e. there exist $\alpha >0$ and $R\geq 0$ such that

### Assumption $\langle x, \nabla U(x)\rangle \geq \alpha \|x\|$ for all $\|x\|\geq R$ (C1)

Now it is sufficient to build a Lyapunov function $V(x)=e^{\gamma \|x\|}$, where $\|x\|=\sqrt{\sum_{i=1}^n x_i^2}$.

Note that $\frac{\partial V(x)}{\partial x_i}= \gamma \frac{x_i}{\|x\|} V(x)$ and $\frac{\partial^2 V(x)}{\partial x_i^2}=\frac{\gamma}{\|x\|} V(x)+ \gamma^2 \frac{x_i^2}{\|x\|^2} V(x) - \gamma \frac{x_i^2}{\|x\|^3}V(x)$. 

In the sequel, we have

$LV(x)=\gamma\left(\frac{n-1}{\|x\|}+\gamma-\frac{x}{\|x\|} \nabla U(x)\right) V(x)$

$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \leq \gamma\left(\frac{n-1}{\|x\|} + \gamma -\alpha \right) V(x)$

$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \leq -\gamma(\alpha-\gamma-\frac{n-1}{R}) V(x) + b 1_{B(0, R)}(x)$.

Hence $V(x)$ is a Lyapunov function provided

\begin{equation}\notag
\lambda = \gamma(\alpha-\gamma-\frac{n-1}{R})>0,
\end{equation}

which suffices to choose $\gamma<\alpha$, a large $R$ and assume the (C1) condition.
 
## Discussions

[1] The construction of Lyapunov function implies a tail decay for the distribution $\mu\propto e^{-U(x)}$ outside the ball $B(0, R)$.

[2] Obtaining a sharper estimate of Poincaré constant may require isoperimetric inequality.]]></content><author><name>Wei Deng</name></author><category term="Functional Inequality" /><summary type="html"><![CDATA[Poincaré (spectral gap) inequality (Bakry et al., 2008) is the first important family of functional inequalities that charaterizes the exponential convergence of a random variable towards the equilibrium.]]></summary></entry><entry><title type="html">Replica Exchange and Variance Reduction</title><link href="http://localhost:4000/posts/replica/" rel="alternate" type="text/html" title="Replica Exchange and Variance Reduction" /><published>2021-05-01T00:00:00-07:00</published><updated>2021-05-01T00:00:00-07:00</updated><id>http://localhost:4000/posts/VR-reSGLD</id><content type="html" xml:base="http://localhost:4000/posts/replica/"><![CDATA[Variance-reduced sampling algorithms {% cite Dubey16 %} {% cite Xu18 %} are not widely adopted in practice. Alternatively, we focus on the energy variance reduction to exploit exponential accelerations but no longer consider the gradient variance reduction. 

To this end, we consider a standard sampling algorithm, the stochastic gradient Langevin dynamics (SGLD), which is a mini-batch numerical discretization of a stochastic differential equation (SDE) as follows:

\begin{equation}
\beta_{k+1}=\beta_k - \eta \frac{N}{n}\nabla \sum_{i\in B} L(x_i\|\beta_k) + \sqrt{2\eta\tau_1} \xi_k,
\end{equation}

where $\beta\in\mathbb{R}^d$, $L(x_i\|\beta)$ is the energy function based on the i-th data point and B denotes a data set of size $n$ simulated from the whole data of size $N$. $\xi$ is a d-dimensional Gaussian vector. It is known that a non-convex $U(\cdot)$ often leads to an exponentially slow mixing rate.

<!--- Simulated annealing is adopted in almost every espect in deep learning, which proposes to anneal temperatures to concentrate the probability measures towards the global optima. Such a strategy, however, fails in uncertainty estimations for reliable predictions. -->

To accelerate the simulations, replica exchange proposes to run multiple stochastic processes with different temperatures, where interactions between different SGLD chains are conducted in a manner that encourages large jumps {% cite yin_zhu_10 %} {% cite chen2018accelerating %} {% cite deng2020 %} {% cite deng_VR %}. 

<!--- The following is a figure that shows the trajectory of the algorithm, where the right path denotes a process driven by a high temperature and the blue one denotes a low-temperature process. -->

<p align="center">
    <img src="/images/reSGLD_exploitation_exploration.png" width="500" height="220" />
</p>

In particular, the parameters swap the positions with a probability $1\wedge S(\beta^{(1)}, \beta^{(2)})$

\begin{equation}
S(\beta^{(1)}, \beta^{(2)})=e^{\left(\frac{1}{\tau_1}-\frac{1}{\tau_2}\right)\left(\frac{N}{n}\sum_{i\in B} L(x_i\|\beta^{(1)})-\frac{N}{n}\sum_{i\in B} L(x_i\|\beta^{(2)})-(\frac{1}{\tau_1}-\frac{1}{\tau_2})\sigma^2\right)},
\end{equation}

where $\sigma^2$ is the variance of the noisy estimators $\sum_{i\in B} L(x_i\|\cdot)$. Under Normality assumptions, the above rule leads to an unbiased swapping probability, which satisfy the detailed balance in a stochastic sense. However, the efficiency of the swaps are significantly reduced due to the requirement of corrections to avoid biases. 

The desire to obtain more effective swaps drives us to design more efficient energy estimators. To reduce the variance of the noisy energy estimator $L(B|\beta^{(h)})=\frac{N}{n}\sum_{i\in B}L(x_i|\beta^{(h)})$ for $h\in\{1,2\}$, we consider an unbiased estimator $L(B|\widehat\beta^{(h)})$ for $\sum_{i=1}^N L(x_i|\widehat\beta^{(h)})$ and a constant $c$, we see that a new estimator $\widetilde L(B| \beta^{(h)})$, which follows
\begin{equation}
    \widetilde L(B|\beta^{(h)})= L(B|\beta^{(h)}) +c\left( L(B|\widehat\beta^{(h)}) -\sum_{i=1}^N L (x_i| \widehat \beta^{(h)})\right),
\end{equation}
is still the unbiased estimator for $\sum_{i=1}^N L(x_i| \beta^{(h)})$. Moreover, energy variance reduction potentially increases the swapping efficiency exponentially given a larger batch size $n$, a small learning rate $\eta$, and a more frequent update of control variate $\widehat \beta$, i.e. a small $m$

\begin{equation}
Var\left(\widetilde L(B\|\beta^{(h)})\right)\leq O\left(\frac{m^2 \eta}{n}\right).
\end{equation}

The following shows a demo that explains how variance-reduced reSGLD works.

<p float="left" align="center">
  <img src="/images/VR-reSGLD/SGLD.gif" width="185" title="SGLD"/>
  <img src="/images/VR-reSGLD/reSGLD_vs_VR_reSGLD.gif" width="340" alt="Made with Angular" title="reSGLD vs VR-reSGLD" />
</p>]]></content><author><name>Wei Deng</name></author><category term="Monte Carlo Methods" /><summary type="html"><![CDATA[Variance-reduced sampling algorithms (Dubey et al., 2016) (Xu et al., 2018) are not widely adopted in practice. Alternatively, we focus on the energy variance reduction to exploit exponential accelerations but no longer consider the gradient variance reduction.]]></summary></entry><entry><title type="html">Dynamic Importance Sampling and Beyond</title><link href="http://localhost:4000/posts/CSGLD/" rel="alternate" type="text/html" title="Dynamic Importance Sampling and Beyond" /><published>2020-11-05T00:00:00-08:00</published><updated>2020-11-05T00:00:00-08:00</updated><id>http://localhost:4000/posts/CSGLD</id><content type="html" xml:base="http://localhost:4000/posts/CSGLD/"><![CDATA[Point estimation tends to over-predict out-of-distribution samples {% cite Balaji17 %} and leads to unreliable predictions. Given a cat-dog classifier, can we predict flamingo as the **unknown** class?

<p align="center">
    <img src="/images/cat_dog.png" width="400" />
</p>

The key to answering this question is **uncertainty**, which is still an open question. Yarin gave a good tutorial on uncertainty predictions using Dropout {% cite YARIN_GAL_blog %}. However, that method tends to underestimate uncertainty due to the nature of variational inference. 

## Importance sampling
How can we give efficient uncertainty quantification for deep neural networks? To answer this question, we first show a baby example. Suppose we are interested in a Gaussian mixture distribution, the standard stochastic gradient Langevin dynamics {% cite Welling11 %} suffers from the local trap issue.

<p align="center">
    <img src="/images/original_density.png" width="250" height="250" />
</p>


To tackle that issue and accelerate computations, we consider importance sampling 

<p align="center">
    <img src="/images/importance_sampling.png" width="600" height="90" />
</p>

That is when the original density is hard to simulate, but the new density is easier. Together with the importance weight, we can obtain an estimate indirectly by sampling from a new density. 

## Build a flattened density

What kind of distribution is easier than the original? A **flattened** distribution!

<p align="center">
    <img src="/images/flat_density.png" width="300" height="300" />
</p>

How to build such a flat density? One famous example is [annealed importance sampling](https://arxiv.org/pdf/physics/9803008.pdf) via high temperatures; another (ours) is to exploit ideas from [Wang-Landau algorithm](https://en.wikipedia.org/wiki/Wang_and_Landau_algorithm) and divide the original density by the **energy PDF**. 
<p align="center">
    <img src="/images/energyPDF.png" width="600" height="60" />
</p>

Given the energy PDF, we can enjoy a **random walk** in the **energy space**. Moreover, the bias caused by simulating from a different density can be adjusted by the importance weight.

## Sample trajectory in terms of learning rates
CSGLD possesses a self-adjusting mechanism to escape local traps. Most notably, it leads to **smaller or even negative learning rates in low energy regions to bounce particles out**.

<p align="center">
    <img src="/images/moves.png" width="700" height="200" />
</p>


## Estimate the energy PDF via stochastic approximation
Since we don’t know the energy PDF in the beginning, we can adaptively estimate it on the fly via **stochastic approximation**. In the long run, we expect that the energy PDF is gradually estimated and we can eventually simulate from the target flat density. Theoretically, this algorithm has a stability property such that the **estimate of energy PDF converges to a unique fixed point regardless of the non-convexity** of the energy function. 

The following is a demo to show how the energy PDF is estimated. In the beginning, CSGLD behaves similarly to SGLD. But soon enough, it moves quite **freely** in the energy space.

<p float="left" align="center">
  <img src="/images/CSGLD/CSGLD_with_PDF.gif" width="200" title="SGLD"/>
  <img src="/images/CSGLD/CSGLD_PDF.gif" width="200" alt="Made with Angular" title="Angular" /> 
</p>

The following result shows [\[code\]](https://github.com/WayneDW/Contour-Stochastic-Gradient-Langevin-Dynamics/blob/master/CSGLD_demo.ipynb) what the flattened and reweighted densities look like.

<p align="center">
    <img src="/images/resample.png" width="600" height="210" title="A mixture example with 9 modes" />
</p>

## Comparison with other methods
We compare CSGLD {% cite CSGLD %} with SGLD {% cite Welling11 %}, {% cite ruqi2020 %}, and {% cite deng2020 %}, and observe that CSGLD is comparable to reSGLD and faster than SGLD and cycSGLD.
<p float="left">
  <img src="/images/CSGLD/SGLD.gif" width="170" title="SGLD"/>
  <img src="/images/CSGLD/cycSGLD.gif" width="170" alt="Made with Angular" title="Angular" />
  <img src="/images/CSGLD/reSGLD.gif" width="170" alt="hello!" title="adam solomon's hello"/>
  <img src="/images/CSGLD/CSGLD.gif" width="170" />
</p>

| Methods   |    Special features  | Cost |
|---------------------------------|:-----------------------:|:---------------------:|
| SGLD (ICML'11) |  None | None |
| Cycic SGLD (ICLR'20) |   Cyclic learning rates  | More cycles |
| Replica exchange SGLD (ICML'20) | Swaps/Jumps | Parallel chains |
| Contour SGLD (NeurIPS'20) | Bouncy moves | Latent vector |

## Summary
Contour SGLD can be viewed as a scalable Wang-Landau algorithm in deep learning. It paves the way for future research in various adaptive biasing force techniques for big data problems. We are working on extensions of this algorithm in both theory and large-scale AI applications. If you like this paper, you can cite

```
@inproceedings{CSGLD,
  title={A Contour Stochastic Gradient Langevin Dynamics Algorithm for Simulations of Multi-modal Distributions},
  author={Wei Deng and Guang Lin and Faming Liang},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}
```

For Chinese readers, you may also find this blog interesting [知乎](https://zhuanlan.zhihu.com/p/267633636).]]></content><author><name>Wei Deng</name></author><category term="Monte Carlo Methods" /><summary type="html"><![CDATA[Point estimation tends to over-predict out-of-distribution samples (Lakshminarayanan et al., 2017) and leads to unreliable predictions. Given a cat-dog classifier, can we predict flamingo as the unknown class?]]></summary></entry></feed>