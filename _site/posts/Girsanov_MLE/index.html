<html>
<head>
    <title>Others</title>
    <meta charset='UTF-8'>
    <meta content='width=device-width, initial-scale=1' name='viewport'/>

    <meta name='description' content='Wei Deng is a machine learning researcher and applied mathematician.'>
    <meta name='keywords' content=''>
    <meta name='author' content='Wei Deng'>

    <link href='/css/blog.css' rel='stylesheet'/>
    <link href='/css/trac.css' rel='stylesheet'/>
    <link href='/css/markdown.css' rel='stylesheet'/>

    
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [ ['$$', '$$'], ["\\[","\\]"]],
      tags: 'ams',
      displayAlign: "center"
    }
  };
  </script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

</head>
<body>
<div class='content'>
    <div class='nav'>
    <ul class='wrap'>
        <li><a href='/'>Home</a></li>
        <li><a href='/publications/'>Publications</a></li>
	<li><a href='/blog/'>Blog</a></li>
    </ul>
</div>

    <div class='front-matter'>
        <div class='wrap'>
            <h1>Others</h1>
            <h4>An application of Girsanov theorem in parameter estimation.</h4>
            <div class='bylines'>
                <div class='byline'>
                    <!-- <h3>Published</h3> -->
                    <p>20 June 2023</p>
                </div>
            </div>
            <div class='clear'></div>
        </div>
    </div>
    <div class='wrap article'>
        <h3 id="maximum-likelihood-estimation">Maximum likelihood estimation</h3>

<p>Given $N$ independent observations, the likelihood function given $\theta=(\mu, \sigma)$ follows that</p>

\[\begin{align}
\mathcal{L}(\{x_i\}_{i=1}^N|\theta)=\prod_{i=1}^N f(x_i|\theta),\notag
\end{align}\]

<p>which models the density of the random variable $X$. The maximum likelihood estimator (MLE) is given by</p>

\[\begin{align}
\widehat\theta=\text{argmax} \mathcal{L}(\mathbf{x}|\theta),\notag
\end{align}\]

<p>where $\mathbf{x}=\{x_i\}_{i=1}^N$. When $X$ is a Gaussian random variable that follows $X\sim \mathcal{N}(\mu, \sigma^2)$. The likelihood function is expressed as</p>

\[\begin{align}\label{MLE}
\mathcal{L}(\{x_i\}_{i=1}^N|\theta)=\bigg(\frac{1}{\sqrt{2\pi \sigma^2}}\bigg)^{N/2} \exp\bigg(-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}\bigg).
\end{align}\]

<p>Taking the gradient w.r.t. $\mu$ and $\sigma^2$, we have</p>

\[\begin{align}
\widehat \mu=\frac{1}{N}\sum_{i=1}^N x_i, \quad \widehat\sigma^2=\frac{1}{N} \sum_{i=1}^N (x_i-\widehat \mu)^2.\notag
\end{align}\]

<h3 id="girsanov-theorem">Girsanov theorem</h3>

<p>Assume we have a diffusion process</p>

\[\begin{align}
\mathrm{d}X_t = b(X_t;\theta)\mathrm{d}t+\sigma\mathrm{d}W_t.\notag
\end{align}\]

<p>We observe the whole path of the process $X_t$ from time $[0, T]$. Denote by $\mathbb{P}_X$ the law of the process on the path space, which is absolutely continuous w.r.t. the Wiener measure. The density of $\mathbb{P}_X$ w.r.t. the Wiener measure is determined by the Radon-Nikodym derivative</p>

\[\begin{align}\label{girsanov}
\frac{\mathrm{d}\mathbb{P}_X}{\mathrm{d}\mathbb{P}_W}=\exp\bigg(\frac{1}{\sigma}\int_0^T b(X_s; \theta)\mathrm{d}W_s-\int_0^T \frac{b^2(X_s;\theta)}{2\sigma^2}\mathrm{d}s \bigg).
\end{align}\]

<p>We can observe a close connection between Eq.\eqref{MLE} and a discrete variant of Eq.\eqref{girsanov}</p>

<p>Remark: While the Girsanov theorem is commonly employed, it is prone to mistakes that can be easily made. Have I made any such errors?</p>

<h3 id="applications">Applications</h3>

<p>Given a stationary Ornstein-Uhlenbeck process, how do you estimate the parameters using MLE <a class="citation" href="#Grigorios_14">(Pavliotis, 2014)</a>..</p>

\[\begin{align}
\mathrm{d}X_t = -\alpha X_t \mathrm{d}t+\sigma\mathrm{d}W_t.\notag
\end{align}\]

<p>Hint: 1) write the likelihood; 2) take the gradient.</p>


    </div>
    <div id='bibliography'>
        <div class='wrap'>
            <ol class="bibliography"><li><span id="Grigorios_14">Pavliotis, G. A. (2014). Stochastic Processes and Applications: Diffusion Processes, the Fokker-Planck and Langevin Equations. <i>Texts in Applied Mathematics</i>.</span></li></ol>
        </div>
    </div>
</div>
</body>
</html>
