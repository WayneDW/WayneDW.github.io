---
title: 'Mean Flow'
subtitle: One-step ultra-fast generations for images and videos
date: 2025-11-03
permalink: /posts/mean_flow/
category: Diffusion
---


Diffusion models {% cite song2021scorebased %} and flow matching {% cite LipmanChenBenHamuNKLe22 %} have become the dominant paradigm for image and video generation. Although iterative refinement eases the optimization challenge, it results in slow sampling. A common acceleration approach is progressive distillation {% cite SalimansH22 %} {% cite LuoH0SZL23 %} {% cite YinG0SDFP24 %}, but it requires a pretrained teacher and offers limited flexibility.


### Consisteny Models

Consistency models {% cite SongDCS23 %} {% cite SongDhariwal24 %} address this by learning a direct mapping from noisy samples to clean data, enforcing self-consistency across noise levels. This enables training from scratch and supports one-step generation without iterative refinement or teacher distillation.

<figure style="text-align: center;">
    <img src="/images/consistency_model.png" width="329" height="231" />
    <!-- <figcaption> Bidirectional mask  $\ \ \qquad$ causal mask $\ \ \qquad$ padding mask $\ \ \qquad$ random mask </figcaption> -->
</figure>

However, consistency models remain heuristic, constraining model outputs rather than a ground-truth field, which often leads to training instability and requires curriculum learning over time discretization.

### Mean Flows


**MeanFlow** {% cite GengD0BKH25 %} avoids both distillation and ad-hoc curriculum learning by modeling the *average velocity field* directly, providing a principled and stable one-step training framework from scratch.


Denote $\mathrm{x \sim p_{\text{data}}}$ and $\mathrm{\epsilon \sim p_{\text{prior}}}$. Consider the linear interpolation $\mathrm{z_t = (1 - t)x + t\epsilon}$. The probability flow ODE yields $\mathrm{\nu_t \equiv z_t' = \epsilon - x}$ ([link](https://www.weideng.org/posts/flow_diffusion_PDE/)), where $$\mathrm{\nu_t \equiv \nu_t(z_t \mid x)}$$ is the conditional velocity. The authors introduce the elegant concept of the **average velocity**:


$$\begin{align}
\mathrm{u(z_t, r, t) \triangleq \frac{1}{t - r} \int_{r}^{t} v(z_{\tau}, \tau) \, d\tau.}\label{def_mf}
\end{align}$$


<figure style="text-align: center;">
    <img src="/images/mean_flow.png" width="605" height="205" />
    <!-- <figcaption> Bidirectional mask  $\ \ \qquad$ causal mask $\ \ \qquad$ padding mask $\ \ \qquad$ random mask </figcaption> -->
</figure>

Taking the derivative w.r.t. $\mathrm{t}$ on both sides of \eqref{def_mf}, we have

$$\begin{align}
\mathrm{(\text{LHS})\quad \dfrac{d z_t}{d t}\partial_z u+\partial_t u} 
&= \mathrm{\frac{\partial}{\partial t} \left( \frac{1}{t-r} \int_{r}^{t} v(z_{\tau}, \tau)\, d\tau \right)}  \notag  \qquad (\text{RHS}) \\[6pt] 
\mathrm{\nu_t\partial_z u+\partial_t u}  &= \mathrm{\frac{1}{t-r} \cdot v(z_t, t) \;-\; \frac{1}{(t-r)^2} \int_{r}^{t} v(z_{\tau}, \tau)\, d\tau} \notag \\[6pt]
\mathrm{\nu_t\partial_z u+\partial_t u}  &= \mathrm{\frac{v(z_t, t)(t-r) - \int_{r}^{t} v(z_{\tau}, \tau)\, d\tau}{(t-r)^2}} \notag \\[6pt]
\mathrm{\nu_t\partial_z u + 0 \cdot \partial_r u +1 \cdot \partial_t u}  &= \mathrm{\frac{v(z_t, t) - u(z_t, r, t)}{t-r}}. \label{eq_} 
\end{align}$$



The derivatives $\mathrm{[\partial_z u, \partial_r u, \partial_t u]}$ on the LHS can be computed via a Jacobianâ€“vector product (JVP) along the tangent vector $\mathrm{[\nu, 0, 1]}$. Let $\mathrm{u_{\theta}}$ parameterize the mean velocity $\mathrm{u}$. The training loss becomes:

$$\begin{align}
\mathrm{E_{t, r}[\|u_{\theta}(z_t, r, t) - sg\big[v(z_t, t) - (t-r)(\nu_t\partial_z u + 0 \cdot \partial_r u +1 \cdot \partial_t u)\big]\|^2_2]},\notag
\end{align}$$

where $\mathrm{sg\big[\cdot\big]}$ denotes the stop-gradient operator. 

After optimizing $\mathrm{u_{\theta}}$, using the probability flow ODE $\mathrm{\nu_t \equiv z_t'}$, sampling is simply:

$$\begin{align}
\mathrm{z_0=z_1 - \int_0^1 \nu_t dt=z_1-u_{\theta}(z_1, 0, 1)}.\notag
\end{align}$$

#### Core Code Snippet


```python
# -----------------------------------------------------------------
# Instantaneous velocity
t, r = self.sample_tr(bz)

e   = jax.random.normal(self.make_rng('gen'), x.shape, dtype=self.dtype)
z_t = (1 - t) * x + t * e
v   = e - x

# Guided velocity
v_g = self.guidance_fn(v, z_t, t, labels, train=False) if self.guidance_eq else v

# Cond dropout (dropout class labels)
y_inp, v_g = self.cond_drop(v, v_g, labels)

# -----------------------------------------------------------------
# Compute u_tr (average velocity) and du_dt using jvp
def u_fn(z_t, t, r):
    return self.u_fn(z_t, t, t - r, y=y_inp, train=train)

dt_dt = jnp.ones_like(t)
dr_dt = jnp.zeros_like(t)
u, du_dt = jax.jvp(u_fn, (z_t, t, r), (v_g, dt_dt, dr_dt))

# -----------------------------------------------------------------
# Compute loss
u_tgt = v_g - jnp.clip(t - r, a_min=0.0, a_max=1.0) * du_dt
u_tgt = jax.lax.stop_gradient(u_tgt)

loss = (u - u_tgt) ** 2
loss = jnp.sum(loss, axis=(1, 2, 3)) # sum over pixels

# Adaptive weighting
adp_wt = (loss + self.norm_eps) ** self.norm_p
loss = loss / jax.lax.stop_gradient(adp_wt)

# -----------------------------------------------------------------
loss = loss.mean()  # mean over batch
```