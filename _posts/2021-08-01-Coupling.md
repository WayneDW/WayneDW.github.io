---
title: 'Couplings and Monte Carlo Methods'
date: 2021-08-01
permalink: /posts/Couplings/
tags:
  - Synchronous Coupling
  - Maximal Coupling
  - Reflection Coupling
---


TBD

The synchronous coupling approach can be used to prove the convergence of stochastic gradient Langevin dynamics for strongly log-concave distributions.

Let $\theta_k\in \mathbb{R}^d$ be the $k$-th iterate of the following stochastic gradient Langevin algorithm.
\begin{align}\label{eq:sgld}
    \theta_{k+1}=\theta_k -\eta \nabla \widetilde f(\theta_k)+\sqrt{2\tau\eta}\xi_k,
\end{align}
where $\eta$ is the learning rate, $\tau$ is the temperature, $\xi_k$ is a standard $d$-dimensional Gaussian vector, and $\nabla \widetilde f(\theta)$ is an unbiased estimate of the exact gradient $\nabla f(\theta)$.




## Assumptions

**Smoothness** We say $f$ is $L$-smooth if for some $L>0$
\begin{align}\label{def:strong_convex}
f(y)\leq f(x)+\langle \nabla f(x),y-x \rangle+\frac{L}{2}|| y-x ||^2_2\quad \forall x, y\in \mathbb{R}^d.
\end{align}


**Strong convexity**
We say $f$ is $m$-strongly convex if for some $m>0$
\begin{align}\label{def:smooth}
f(x)\geq f(y)+\langle \nabla f(y),x-y \rangle + \frac{m}{2} || y-x ||_2^2\quad \forall x, y\in \mathbb{R}^d.
\end{align}


**Bounded variance** The variance of stochastic gradient $\nabla \widetilde f(x)$ in each device is upper bounded such that
\begin{align}\label{def:variance}
\mathbb{E}[||\nabla \widetilde f(x)-\nabla f(x)||^2] \leq \sigma^2 d,\quad \forall x\in \mathbb{R}^d.
\end{align}




## A Crude Result/ Theorem

Assume assumptions \ref{def:strong_convex}, \ref{def:smooth}, and \ref{def:variance} hold. For any learning rate $\eta \in (0 , \min \{ 1, {m}/{L^2} \} )$  and $\|\| \theta_0-\theta_* \|\| \leq \sqrt{d} {D}$, where $\theta_*$ is a stationary point. Then


\begin{align}
W_2(\mu_k, \pi) \leq e^{-{mk\eta}/{2}} \cdot 2 ( \sqrt{d} {D} + \sqrt{d/m} ) + \sqrt{ 2d (\sigma^2+L^2 G\eta) / m^2},
\end{align}

where $\mu_k$ denotes the probability measure of $\theta_k$ and $G:=25(\tau+m\mathcal{D}^2+\sigma^2)$.


## Proof
Denote $\theta_t$ as the continuous-time interpolation of the stochastic gradient Langevin dynamics as follows

\begin{align}\label{eq:continuous_interpolation}
d \theta_t = - \nabla \widetilde f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) d t + \sqrt{2\tau} d \widetilde W_t,
\end{align}

where ${\theta}_0=\theta_0$. For any $k\in \mathbb{N}^{+}$ and a time $t$ that satisfies $t=k\eta$, it is apparent that $\widehat\mu_t=\mathcal{L}({\theta}_t)$ is the same as $\mu_k=\mathcal{L}(\theta_k)$, where $\mathcal{L}(\cdot)$ denotes a distribution of a random variable. In addition, we define an auxiliary process $(\beta_t)$ that starts from the stationary distribution $\pi$

\begin{align}
d \beta_t = - \nabla f(\beta_t) d t + \sqrt{2\tau} d W_t.
\end{align}



Consider Itô's formula for the sequence of $\frac{1}{2}  \|\| \theta_t - \beta_t \|\| ^2$

$\quad\frac{1}{2} d  \|\| \theta_t - \beta_t \|\|^2\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad$ 
$= \langle \theta_t - \beta_t, d \theta_t - d \beta_t \rangle + \mathrm{Tr}[ d^2 \theta_t - d^2 \beta_t ]\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad$
$= \langle \theta_t - \beta_t, (\nabla f(\beta_t) -\nabla\widetilde  f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) ) d t + \sqrt{2\tau} ( d \widetilde W_t - d W_t ) \rangle + 2\tau \mathrm{Tr}[ d^2 \widetilde W_t - d^2 W_t ].$


Taking $\widetilde W_t=W_t$ defines a synchronous coupling. Arrange the terms

$\ \ \ \frac{1}{2} d \|\| \theta_t - \beta_t \|\|^2$
$= \langle \theta_t - \beta_t, \nabla f(\beta_t)-\nabla f(\theta_t) \rangle d t+ \langle \theta_t - \beta_t,  \nabla f(\theta_{t}) - \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor})  \rangle d t\qquad\qquad\qquad\qquad\qquad\qquad$
$\qquad \qquad\qquad+ \langle \theta_t - \beta_t, \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) - \nabla \widetilde f(\widehat \theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) \rangle d t$
$\leq - m \|\| \theta_t - \beta_t \|\|^2 d t + \frac{m}{4} \|\| \theta_t - \beta_t \|\|^2 d t + \frac{1}{m}  \|\| \nabla f(\theta_{t}) - \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor})  \|\|^2 d t $
$\qquad\qquad  + \frac{m}{4} \|\| \theta_t - \beta_t \|\|^2 d t + \frac{1}{m} \|\| \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) - \nabla \widetilde f(\widehat \theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) \|\|^2 d t$
$\leq  - \frac{m}{2} \|\| \theta_t - \beta_t \|\|^2 d t + \frac{d\sigma^2}{m} d t +\frac{1}{m} \|\| \nabla f(\theta_{t}) - \nabla f(\theta_{\eta\lfloor\frac{t}{\eta} \rfloor}) \|^2  d t$
$\leq  - \frac{m}{2} \|\| \theta_t - \beta_t \|\|^2 d t + \frac{d\sigma^2}{m} d t+ \frac{L^2}{m} \|\| \theta_{t} - \theta_{\eta\lfloor\frac{t}{\eta} \rfloor} \|\|^2  d t$

where the first inequality follows from $ab\leq  (\frac{\sqrt{m}}{2}a)^2+({\frac{1}{\sqrt{m}}}b)^2$ and the strong-convexity property \ref{def:strong_convex}; in particular, we don't attempt to optimize the constants of $-\frac{m}{2}$ for the item $\|\| \theta_t - \beta_t \|\|^2$; the second and third inequalities follow by bounded variance assumption \ref{def:variance} and the smoothness assumption \ref{def:smooth}, respectively.


Now apply Grönwall's inequality to the preceding inequality and take expectation respect to a coupling $(\theta_t, \beta_t) \sim \Gamma(\widehat\mu_t,\pi)$
\begin{align}\label{eq:1st_gronwall}
     \mathbb{E}{ \|\theta_t - \beta_t \|\|^2}\leq  \mathbb{E}{\| \theta_0 - \beta_0 \|\|^2} e^{-mt}+\frac{2}{m}\int_0^t g(d\sigma^2+ L^2\underbrace{\mathbb{E}{ \| \theta_{s} - \theta_{\eta\lfloor\frac{s}{\eta} \rfloor} \|\|^2 }}_{\mathcal{I}: \text{Discretization error}} g) e^{-(t-s)m} d s. 
\end{align}


Plugging some estimate of $\mathcal{I}$ into Eq.~\eqref{eq:1st_gronwall}, we have
\begin{align}
    \mathbb{E}{ \|\| \theta_t - \beta_t \|\|^2 }&\leq  \mathbb{E}{\| \theta_0 - \beta_0 \|\|^2} e^{-mt}+\frac{2d}{m} (\sigma^2+L^2 G\eta) \int_0^t  e^{-(t-s)m} d s\\
     &\leq \mathbb{E}{\| \theta_0 - \beta_0 \|^2} e^{-mt}+\frac{2d}{m^2} (\sigma^2+L^2 G\eta).
\end{align}

Recall that $\theta_k$ and $\widehat\theta_{t\eta}$ have the same distribution $\mu_k$. 


By the definition of $W_2$ distance, we have
$W_2(\mu_k, \pi)$
$\leq e^{-{mk\eta}/{2}} \cdot W_2(\mu_0, \pi) + \sqrt{ 2d (\sigma^2+L^2 G\eta) / m^2}$
$\leq e^{-{mk\eta}/{2}} \cdot 2 (\| \theta_0 - \theta_* \| +  \sqrt{d/m} )+ \sqrt{ 2d(\sigma^2+L^2 G\eta) / m^2}$
$\leq e^{-{mk\eta}/{2}} \cdot 2 ( \sqrt{d} {\cal D} +  \sqrt{d/m} )+  \sqrt{ 2 d(\sigma^2+L^2 G\eta) / m^2},$


\begin{align}
W_2(\mu_k, \pi) 
%\leq \left(\mathbb{E}{ \| \theta_{k\eta} - \beta_{k\eta} \|^2}\right)^{1/2}
\leq & ~ e^{-{mk\eta}/{2}} \cdot W_2(\mu_0, \pi) + \sqrt{ 2d (\sigma^2+L^2 G\eta) / m^2} \\
\leq & ~ e^{-{mk\eta}/{2}} \cdot 2 (\| \theta_0 - \theta_* \| +  \sqrt{d/m} )+ \sqrt{ 2d(\sigma^2+L^2 G\eta) / m^2} \\
\leq & ~ e^{-{mk\eta}/{2}} \cdot 2 ( \sqrt{d} {\cal D} +  \sqrt{d/m} )+  \sqrt{ 2 d(\sigma^2+L^2 G\eta) / m^2},
\end{align}
where the first inequality follows by applying $(a+b)^{1/2}\leq |a|^{1/2}+|b|^{1/2}$, the second one follows by Lemma \ref{lem:W2_init_bound}, and the last step follows from assumption on $ \|\| \theta_0 - \theta_* \|\|$.




