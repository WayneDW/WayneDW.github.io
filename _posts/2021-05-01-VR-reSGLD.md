---
title: 'Acceleration via Replica Exchange and Variance Reduction'
date: 2021-05-01
permalink: /posts/replica/
tags:
  - replica exchange
  - parallel tempering
  - simulations of multi-modal distributions
  - variance reduction
---

Despite the popularity for the gradient-based variance reduction [1,2], a discrepancy between theory and practice is whether we should avoid the gradient noise in non-convex problems. To fill in the gap, we only focus on the energy variance reduction to exploit exponential accelerations but no longer consider the gradient variance reduction.

A standard sampling algorithm is the stochastic gradient Langevin dynamics (SGLD), which is a mini-batch numerical discretization of a stochastic differential equation (SDE) as follows:

$\beta_{k+1}=\beta_k - \eta \nabla \widetilde U(\beta_k) + \sqrt{2\tau_1} \xi_k$,

where $\beta\in\mathbb{R}^d$, $U(\cdot)$ is a energy function and $\xi$ is a d-dimensional Gaussian vector. It is known that a non-convex $U(\cdot)$ often leads to an exponentially slow mixing rate.

Simulated annealing is adopted in almost every espect in deep learning, which proposes to anneal temperatures to concentrate the probability measures towards the global optima. Such a strategy, however, fails in uncertainty estimations for reliable predictions. To accelerate the simulations, replica exchange proposes to run multiple stochastic processes with different temperatures, where interactions between different SGLD chains are conducted in a manner that encourages large jumps.

swaps between different SGLD chains are conducted with a probability $1\wedge S(\bbeta)$.

<p align="center">
    <img src="/images/reSGLD_exploitation_exploration.png" width="500" height="250" />
</p>

In particular, the parameters swap the positions with a probability $1\wedge S(\beta^{(1)}, \beta^{(2)})$

$S(\beta^{(1)}, \beta^{(2)})=e^{(\frac{1}{\tau_1}-\frac{1}{\tau_2})(\widetilde U(\beta^{(1)})-\widetilde U(\beta^{(2)})-(\frac{1}{\tau_1}-\frac{1}{\tau_2})\sigma^2)}$,

where $\sigma^2$ is the variance of the noisy estimators $\widetilde U(\cdot)$. Under Normality assumptions, the above rule leads to an unbiased swapping probability, which satisfy the detailed balance in a stochastic sense.




swapping rate r(1 ∧ S(β
(1)
t
, β
(2)
t
))dt, where the constant
r ≥ 0 is the swapping intensity, and S(·, ·) satisfies




<p float="left" align="center">
  <img src="/images/VR-reSGLD/SGLD.gif" width="185" title="SGLD"/>
  <img src="/images/VR-reSGLD/reSGLD_vs_VR_reSGLD.gif" width="340" alt="Made with Angular" title="reSGLD vs VR-reSGLD" />
</p>

Coming soon

## References:

1. Dubey, Reddi, Poczos, Smola, Xing, Williamson. Variance Reduction in Stochastic Gradient Langevin Dynamics. NeurIPS'16.
2. Xu, Chen, Zou, Gu. Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization. NeurIPS'18.
3. Chen, Chen, Dong, Peng, Wang. Accelerating Nonconvex Learning via Replica Exchange Langevin Diffusion. ICLR'19.
4. Deng, Feng, Gao, Liang, Lin. Non-Convex Learning via Replica Exchange Stochastic Gradient MCMC. ICML'20.
5. Deng, Feng, Karagiannis, Lin, Liang. Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction. ICLR'21.
6. George Yin and Chao Zhu. Hybrid Switching Diffusions: Properties and Applications. Springer, 2010.
