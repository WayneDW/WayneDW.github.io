---
title: 'Acceleration via Replica Exchange and Variance Reduction'
date: 2021-05-01
permalink: /posts/replica/
tags:
  - replica exchange
  - parallel tempering
  - simulations of multi-modal distributions
  - variance reduction
---

Despite the popularity for conducting variance reduction on the gradient [1,2], such an idea is not widely adopted in practice. To fill in the gap, we only focus on the energy variance reduction to exploit exponential accelerations but no longer consider the gradient variance reduction. 

To this end, we consider a standard sampling algorithm, the stochastic gradient Langevin dynamics (SGLD), which is a mini-batch numerical discretization of a stochastic differential equation (SDE) as follows:

$\beta_{k+1}=\beta_k - \eta \frac{N}{n}\nabla \sum_{i\in B} L(x_i\|\beta_k) + \sqrt{2\tau_1} \xi_k$,

where $\beta\in\mathbb{R}^d$, $L(x_i\|\beta)$ is the energy function based on the i-th data point and B denotes a data set of size $n$ simulated from the whole data of size $N$. $\xi$ is a d-dimensional Gaussian vector. It is known that a non-convex $U(\cdot)$ often leads to an exponentially slow mixing rate.

<!--- Simulated annealing is adopted in almost every espect in deep learning, which proposes to anneal temperatures to concentrate the probability measures towards the global optima. Such a strategy, however, fails in uncertainty estimations for reliable predictions. -->

To accelerate the simulations, replica exchange proposes to run multiple stochastic processes with different temperatures, where interactions between different SGLD chains are conducted in a manner that encourages large jumps. 

<!--- The following is a figure that shows the trajectory of the algorithm, where the right path denotes a process driven by a high temperature and the blue one denotes a low-temperature process. -->

<p align="center">
    <img src="/images/reSGLD_exploitation_exploration.png" width="500" height="250" />
</p>

In particular, the parameters swap the positions with a probability $1\wedge S(\beta^{(1)}, \beta^{(2)})$

$S(\beta^{(1)}, \beta^{(2)})=e^{\left(\frac{1}{\tau_1}-\frac{1}{\tau_2}\right)\left(\widetilde U(\beta^{(1)})-\widetilde U(\beta^{(2)})-(\frac{1}{\tau_1}-\frac{1}{\tau_2})\sigma^2\right)}$,

where $\sigma^2$ is the variance of the noisy estimators $\widetilde U(\cdot)$. Under Normality assumptions, the above rule leads to an unbiased swapping probability, which satisfy the detailed balance in a stochastic sense. Moreover, the efficiency of the swaps are greatly affected due to the requirement of corrections to avoid biases. The desire to obtain more effective swaps drives us to design more efficient energy estimators. To reduce the variance of the noisy energy estimator $L(B|\beta^{(h)})=\frac{N}{n}\sum_{i\in B}L(x_i|\beta^{(h)})$ for $h\in\{1,2\}$, we consider an unbiased estimator $L(B|\widehat\beta^{(h)})$ for $\sum_{i=1}^N L(x_i|\widehat\beta^{(h)})$ and a constant $c$, we see that a new estimator $\widetilde L(B| \beta^{(h)})$, which follows
\begin{equation}
    \widetilde L(B|\beta^{(h)})= L(B|\beta^{(h)}) +c\left( L(B|\widehat\beta^{(h)}) -\sum_{i=1}^N L (x_i| \widehat \beta^{(h)})\right),
\end{equation}
is still the unbiased estimator for $\sum_{i=1}^N L(x_i| \beta^{(h)})$. Moreover, energy variance reduction potentially increases the swapping efficiency exponentially given a larger batch size $n$, a small learning rate $\eta$, and a more frequent update of control variate, i.e. a small $m$

$Var\left(\widetilde L(B\|\beta^{(h)})\right)\leq min\{ \mathcal{O}\left(\frac{m^2 \eta}{n}\right), Var(\frac{N}{n}\sum_{i\in B} L(x_i\| \beta^{(h)}))+Var(\frac{N}{n}\sum_{i\in B} L(x_i\| \widehat\beta^{(h)}))\}.$

The following shows a demo that explains how variance-reduced reSGLD works.

<p float="left" align="center">
  <img src="/images/VR-reSGLD/SGLD.gif" width="185" title="SGLD"/>
  <img src="/images/VR-reSGLD/reSGLD_vs_VR_reSGLD.gif" width="340" alt="Made with Angular" title="reSGLD vs VR-reSGLD" />
</p>


## References:

1. Dubey, Reddi, Poczos, Smola, Xing, Williamson. Variance Reduction in Stochastic Gradient Langevin Dynamics. NeurIPS'16.
2. Xu, Chen, Zou, Gu. Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization. NeurIPS'18.
3. Chen, Chen, Dong, Peng, Wang. [Accelerating Nonconvex Learning via Replica Exchange Langevin Diffusion](https://arxiv.org/pdf/2007.01990.pdf). ICLR'19.
4. Deng, Feng, Gao, Liang, Lin. [Non-Convex Learning via Replica Exchange Stochastic Gradient MCMC](https://arxiv.org/pdf/2010.01084.pdf). ICML'20.
5. Deng, Feng, Karagiannis, Lin, Liang. [Accelerating Convergence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction](https://arxiv.org/pdf/2010.01084.pdf). ICLR'21.
6. George Yin and Chao Zhu. Hybrid Switching Diffusions: Properties and Applications. Springer, 2010.
