---
title: 'Dynamic Importance Sampling'
date: 2020-12-01
permalink: /posts/2020/12/blog-post-4/
tags:
  - importance sampling
  - uncertainty quantification
  - mean field
  - flattened distribution
  - stochastic approximation
  - weighted ensemble
---

Point estimation in deep learning tends to over-predict results [1] and leads to unreliable predictions for out-of-distribution samples. Suppose we are given a cat-dog classifier. What the prediction will be for an input of flamingo? Can we predict flamingo as the ``third'' unknown class?

<p align="center">
    <img src="/images/cat_dog.png" />
</p>

A reliable model should not only make the right decision among potential candidates but also cast doubts on irrelevant choices. The key to building such a model is to quantify uncertainty efficiently and correctly. However, it is still an open question in deep learning. Regarding efficiency, Yarin already gives a good tutorial on uncertainty predictions using Dropout [2]. However, that method tend to underestimate the uncertainty due to the nature of variational inference. 


How can we give accurate uncertainty quantification for deep learning? Suppose we are interested in the simulation of a Gaussian mixture distribution, the standard stochastic gradient Langevin dynamics will suffer from the local trap issue and spends too much time in a local region.  

<p align="center">
    <img src="/images/original_density.png" width="300" height="300" />
</p>


To alleviate the local trap problem, we may consider to simulate from a flattened distribution

<p align="center">
    <img src="/images/flat_density.png" width="300" height="300" />
</p>

Where does the flat density comes from? We exploit ideas from the Wang-Landau algorithm. That is we divide the original density by the **energy PDF**.

If we know the energy PDF, we can simulate from the target flat density, which yields significant accelerations. Moreover, the bias caused by simulating from a different target can be adjusted by the importance weight.

But we donâ€™t know the energy PDF in the beginning. The solution is to adaptively estimate it on the fly via stochastic approximation. In the long run, we expect that theta is gradually estimated and we can eventually simulate from the target flat density. The following is a demo to show how the energy PDF is gradually estimated. You can see in the beginning before the energy PDF is estimated, CSGLD behaves similar to SGLD. But soon enough, it moves quite freely in the parameter domain.

<p float="left" align="center">
  <img src="/images/CSGLD/CSGLD_with_PDF.gif" width="200" title="SGLD"/>
  <img src="/images/CSGLD/CSGLD_PDF.gif" width="200" alt="Made with Angular" title="Angular" /> 
</p>


To summarize our method, our method induces an adaptive learning rate schedule to escape local traps: it leads to **smaller or even negative learning rates in low energy regions to bounce out of local region**. 

<p align="center">
    <img src="/images/moves.png" width="800" height="200" />
</p>


We also compare our methods with the existing state-of-art sampling algorithms and observe that CSGLD is comparable to reSGLD and much faster than SGLD and cycSGLD.
<p float="left">
  <img src="/images/CSGLD/SGLD.gif" width="185" title="SGLD"/>
  <img src="/images/CSGLD/cycSGLD.gif" width="185" alt="Made with Angular" title="Angular" />
  <img src="/images/CSGLD/reSGLD.gif" width="185" alt="hello!" title="adam solomon's hello"/>
  <img src="/images/CSGLD/CSGLD.gif" width="185" />
</p>

| Methods   |      Speed      | Special features  | Cost |
|----------|:-------------:|:-------------:|:-------------:|
| SGLD (ICML'11) |  Extremely slow | None | None |
| Cycic SGLD (ICLR'20) |    Medium   | Cyclic learning rates  | More cycles |
| Replica exchange SGLD (ICML'20) | Fast | Swaps/Jumps | Parallel chains |
| Contour SGLD (NeurIPS'20) | Fast | Bouncy moves | Latent vector |




## References:

1. Lakshminarayanan, etc. Simple and Scalable Predictive Uncertainty Estimation using Deep Ensemble. NeurIPS'17.

2. Yarin Gal. [What My Deep Model Doesn't Know and Why Should I Care About Uncertainty?](https://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html)

3. Max Welling, Yee Whye Teh. [Bayesian Learning via Stochastic Gradient Langevin Dynamics](https://pdfs.semanticscholar.org/aeed/631d6a84100b5e9a021ec1914095c66de415.pdf). ICML'11

4. R. Zhang, etc. [Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning](https://arxiv.org/pdf/1902.03932.pdf). ICLR'20

5. W. Deng, etc. [Non-convex Learning via Replica Exchange Stochastic Gradient MCMC](https://arxiv.org/pdf/2008.05367.pdf). ICML'20.

6. W. Deng, G. Lin, F. Liang. [A Contour Stochastic Gradient Langevin Dynamics Algorithm for Simulations of Multi-modal Distributions](https://arxiv.org/pdf/2010.09800.pdf). NeurIPS'20.

