---
title: 'Dynamic Importance Sampling'
date: 2020-12-01
permalink: /posts/2020/12/blog-post-4/
tags:
  - importance sampling
  - uncertainty quantification
  - mean field
  - flattened distribution
---

Point estimation in deep learning tends to over-predict results [1]. It gives good predictions if the testing data is similar to the training data but fails for out-of-distribution samples.

Suppose we are given a cat-dog classifier. What the prediction will be for an input of flamingo?
![Over-prediction in deep learning](/images/cat_dog.png)



A reliable model should not only make the right decision among potential candidates but also cast doubts on irrelevant choices.


The key to solving that problem is quantify uncertainty efficiently and correctly. Uncertainty quantification for unimodal distribution is a standard result. However, it is still an ongoing topic in deep learning. Regarding efficiency, Yarin already gives a pretty good tutorial talking about uncertainty predictions using Dropout. [2]. However, that method belongs to the class of variance inference, which tend to underestimate the uncertainty. 


So how can we give a more correct uncertainty quantification for deep learning? Suppose we are interested in the simulation of a Gaussian mixture distribution, the standard stochastic gradient Langevin dynamics will suffer from the local trap issue and spends too much time in a local region.  

<img src="/images/original_density.png" width="400" height="400" />


To alleviate the local trap problem, we may consider to simulate from a flattened distribution

<img src="/images/flat_density.png" width="400" height="400" />


Where does the flat density comes from?

We exploit ideas from the Wang-Landau algorithm. That is




If we know theta_{\star}, then we can simulate from a flat density, so that the simulation can be much accelerated. Moreover, theta acts as the importance weight. By reweighting the samples, we can recover the original density.


How to learn theta? We donâ€™t know it in the beginning, but we can adaptively estimate theta on the fly. That is we simulate the parameter and adaptively estimate theta, in the long run, we expect that theta is gradually estimated and we can eventually simulate from the target flat density.



<p float="left">
  <img src="/images/CSGLD/SGLD.gif" width="150" title="SGLD"/>
  <img src="/images/CSGLD/cycSGLD.gif" width="150" alt="Made with Angular" title="Angular" /> 
  <img src="/images/CSGLD/reSGLD.gif" width="150" alt="hello!" title="adam solomon's hello"/>
  <img src="/images/CSGLD/CSGLD.gif" width="150" />
</p>



| Methods   |      Speed      | Special features  | Cost |
|----------|:-------------:|:-------------:|:-------------:|
| SGLD (ICML'11) |  Extremely slow | None | None |
| Cycic SGLD (ICLR'20) |    Medium   | Cyclic learning rates  | More cycles |
| Replica exchange SGLD (ICML'20) | Fast | Swaps/Jumps | Parallel chains |
| Contour SGLD (NeurIPS'20) | Fast | Bouncy moves | Latent vector |



The following is a demo to show how the latent vector is gradually estimated
<p float="left">
  <img src="/images/CSGLD/CSGLD_with_PDF.gif" width="200" title="SGLD"/>
  <img src="/images/CSGLD/CSGLD_PDF.gif" width="200" alt="Made with Angular" title="Angular" /> 
</p>





[1] Lakshminarayanan, etc. Simple and Scalable Predictive Uncertainty Estimation using Deep Ensemble. NeurIPS, 2017.

[2] Yarin Gal. [What My Deep Model Doesn't Know and Why Should I Care About Uncertainty?](https://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html)
