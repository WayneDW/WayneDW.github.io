---
permalink: /
title: "A Sampler’s Blog"
excerpt: "what is this?"
author_profile: true
---

<p align="center"> <img class="img-circle img-200" width="100%" src="images/monte_carlo_city.png"></p>

<!-- title: "Nothing but Sampling" -->

<!-- This space explores sequential sampling techniques with a focus on the understanding, scaling, and alignment of diffusion(-language) models.  -->

<!-- This space is for those interested in understanding, scaling, aligning, and applying diffusion(-language) models. -->

This space is for the understanding, scaling, aligning, and applications of diffusion language models. Much of the thinking is inspired by various samplers and transformer variants.

 <!-- market simulations. -->

<!--  **Diffusion Models** – Improving the transport efficiency for diffusion generations. -->

<!-- **Sequential Sampling** – Alignment and fine-tuning for diffusion Language model.

**Market Simulation** – Diffusion market simulators for hedging and risk control. -->

<!-- Apr, 2025. Honored to present **On Generation of Latent Diffusion in the FX Market** at Columbia's [Practitioners’ Seminar 2025](https://www.math.columbia.edu/mafn/practitioners-seminar-2025/). -->


<!---  I actively contribute to open-source projects such as [Contour Sampler in JAX](https://github.com/blackjax-devs/blackjax) and [NLP in Finance](https://github.com/WayneDW/Sentiment-Analysis-in-Event-Driven-Stock-Price-Movement-Prediction). -->

<!---  I got my Ph.D. in applied math at Purdue University in Dec 2021 and my thesis is <a href="https://hammer.purdue.edu/articles/thesis/Non-convex_Bayesian_Learning_via_Stochastic_Gradient_Markov_Chain_Monte_Carlo/17161718" target="">Non-convex Bayesian Learning via Stochastic Gradient MCMC</a>. 

Interns I (* directly) work with: [Shikai Fang\*](https://users.cs.utah.edu/~shikai/), [Yixin Tan\*](https://scholar.google.com/citations?user=3AGaybIAAAAJ&hl=zh-CN), [Kevin Rojas\*](https://kevinrojas1499.github.io/), [Marin Biloš](https://scholar.google.com/citations?user=2WDzslAAAAAJ&hl=en), [Sarthak Mittal](https://sarthmit.github.io/).  -->



<!--- a I got my Ph.D. at Purdue University in 2021, where I was advised by Prof. [Guang Lin](https://www.math.purdue.edu/~lin491/) and <a href="https://www.stat.purdue.edu/~fmliang/" target="_blank">Faming Liang</a>. -->


Feel free to contact me at: firstnamelastname056@gmail.com


<style>
  .pub-links a.deep-blue {
    /* color: #3366cc; */
    /* color: #205ea6; */
    color: #1a4b8b;
  }
</style>

<ul class="pub-links" style="list-style: none; padding: 0; display: flex; gap: 1rem;">
  <li><a href="https://scholar.google.com/citations?user=IYiyxssAAAAJ&hl=en" target="_blank"  class="deep-blue">Scholar</a></li>
  <li><a href="https://github.com/WayneDW" target="_blank" class="deep-blue">Github</a></li>
  <li><a href="https://twitter.com/dwgreyman" target="_blank" class="deep-blue">Twitter</a></li>
  <li><a href="https://openreview.net/profile?id=~Wei_Deng1" target="_blank" class="deep-blue">OpenReview</a></li>
</ul>



Welcome to read our paper [Didi-Instruct](https://www.arxiv.org/pdf/2509.25035) on Ultra-Fast Language Generation!


<!-- <li><a href="https://hammer.purdue.edu/articles/thesis/Non-convex_Bayesian_Learning_via_Stochastic_Gradient_Markov_Chain_Monte_Carlo/17161718" target="_blank"  class="deep-blue">Thesis</a></li> -->



<!-- Services


Reviewers: ICML, NeurIPS, ICLR, AISTAT, AAAI, IJCAI. -->

<!-- ====== -->
La pensée n'est qu'un écliar au milieu d'une longue nuit. Mais c'est cet éclair qui est tout. - Poincaré
